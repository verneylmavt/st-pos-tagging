{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tree import Tree\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackedTransformerEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code sets the random seed for reproducibility across random, NumPy, and PyTorch operations. This ensures consistent results by fixing the seed for both CPU and GPU computations.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code loads the parsed sentences from the Penn Treebank corpus, converting them into a list of tree structures for further processing.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = list(treebank.parsed_sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code iterates through each tree to count the frequency of words and POS tags. It stores these counts in dictionaries to facilitate vocabulary construction.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = defaultdict(int)\n",
    "pos_freq = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in trees:\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.height() == 2:\n",
    "            word = subtree.leaves()[0].lower()\n",
    "            pos = subtree.label()\n",
    "            word_freq[word] += 1\n",
    "            pos_freq[pos] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code constructs mappings from words and POS tags to unique indices, including special tokens for padding and unknown words. It also creates reverse mappings for later use in decoding predictions.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 2\n",
    "\n",
    "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "for word, freq in word_freq.items():\n",
    "    if freq >= min_freq:\n",
    "        word2idx[word] = len(word2idx)\n",
    "        \n",
    "pos2idx = {'<PAD>': 0}\n",
    "for pos, freq in pos_freq.items():\n",
    "    pos2idx[pos] = len(pos2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "idx2pos = {idx: pos for pos, idx in pos2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code defines a function to load pre-trained GloVe embeddings. It initializes an embedding matrix with random values and replaces them with GloVe vectors for words present in the vocabulary.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_glove(glove_url, download_path, extract_to):\n",
    "    urllib.request.urlretrieve(glove_url, download_path)\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_file_path, embedding_dim, word2idx):\n",
    "    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), embedding_dim))\n",
    "    embeddings[word2idx['<PAD>']] = np.zeros(embedding_dim)\n",
    "\n",
    "    glove_url = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "    glove_zip_path = os.path.join(os.path.dirname(glove_file_path), \"glove.6B.zip\")\n",
    "    glove_dir = os.path.dirname(glove_file_path)\n",
    "\n",
    "    if not os.path.isfile(glove_file_path):\n",
    "        if not os.path.exists(glove_dir):\n",
    "            os.makedirs(glove_dir)\n",
    "        download_glove(glove_url, glove_zip_path, glove_dir)\n",
    "\n",
    "    with open(glove_file_path, 'r', encoding='utf8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            values = line.strip().split()\n",
    "            if not values:\n",
    "                continue\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            if word in word2idx:\n",
    "                embeddings[word2idx[word]] = vector\n",
    "\n",
    "    return torch.tensor(embeddings, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "embedding_matrix = load_glove_embeddings(\"../../data/glove.6B.200d/glove.6B.200d.txt\", embedding_dim, word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code defines a custom dataset class for the Treebank data and a collate function to handle batching and padding. It splits the data into training and validation sets and creates corresponding DataLoader instances.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreebankDataset(Dataset):\n",
    "    def __init__(self, trees, word2idx, pos2idx):\n",
    "        self.trees = trees\n",
    "        self.word2idx = word2idx\n",
    "        self.pos2idx = pos2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trees)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tree = self.trees[idx]\n",
    "        words = [word.lower() for word in tree.leaves()]\n",
    "        pos_tags = [subtree.label() for subtree in tree.subtrees() if subtree.height() == 2]\n",
    "        word_indices = [self.word2idx.get(word, self.word2idx['<UNK>']) for word in words]\n",
    "        pos_indices = [self.pos2idx.get(tag, self.pos2idx['<PAD>']) for tag in pos_tags]\n",
    "        return torch.tensor(word_indices, dtype=torch.long), torch.tensor(pos_indices, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, pos_tags = zip(*batch)\n",
    "    lengths = torch.tensor([len(s) for s in sentences], dtype=torch.long)\n",
    "    padded_sentences = nn.utils.rnn.pad_sequence(sentences, batch_first=True, padding_value=word2idx['<PAD>'])\n",
    "    padded_pos_tags = nn.utils.rnn.pad_sequence(pos_tags, batch_first=True, padding_value=pos2idx['<PAD>'])\n",
    "    return padded_sentences, padded_pos_tags, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trees, val_trees = train_test_split(trees, test_size=0.1, random_state=42)\n",
    "train_dataset = TreebankDataset(train_trees, word2idx, pos2idx)\n",
    "val_dataset = TreebankDataset(val_trees, word2idx, pos2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_iter = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn, \n",
    "    num_workers=0\n",
    ")\n",
    "val_iter = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code defines a positional encoding module that adds positional information to word embeddings. This helps the model understand the order of words in a sequence.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPositionalEncoding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=5000):\n",
    "        super(SPositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Positional Encoding Tensor for Representing Position Information\n",
    "        pe = torch.zeros(max_len, embedding_dim)\n",
    "        # Tensor for Position Indices\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        # Divisor Term Tensor for Scaling Positions\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-np.log(10000.0) / embedding_dim))\n",
    "        # Sine Component of Positional Encoding\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # Cosine Component of Positional Encoding (Adjusted for Odd Dimensions)\n",
    "        if embedding_dim % 2 == 1:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # Adding Batch Dimension to Positional Encoding\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # Registering Positional Encoding as Buffer\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Addition of Positional Encoding to Input Tensor\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code defines a transformer-based model for POS tagging. The model includes embedding layers, positional encoding, transformer encoder layers, dropout, and a fully connected layer for outputting POS tag probabilities.\n",
    "\n",
    "• Token Embedding Layer\n",
    "The model begins with an embedding layer that maps input token indices into dense vectors of fixed size. This layer can be initialized with a pre-trained embedding matrix, allowing the model to leverage semantic knowledge from external datasets. The embeddings are fine-tuned during training to adapt to the specific task of POS tagging. A padding index is used to handle sequences of varying lengths, ensuring that padded tokens do not affect the training process.\n",
    "\n",
    "• Positional Encoding\n",
    "Since transformers lack inherent sequential processing, a positional encoding layer (SPositionalEncoding) augments the token embeddings with positional information. This step ensures that the transformer can recognize the order of tokens in a sequence, which is critical for tasks like POS tagging where syntactic context depends on token order.\n",
    "\n",
    "• Transformer Encoder\n",
    "The transformer encoder forms the core of the model. It consists of:\n",
    "- Multi-Head Self-Attention: Allows each token to attend to all others in the sequence, capturing long-range dependencies and contextual relationships.\n",
    "- Feedforward Layers: Apply non-linear transformations to the outputs of the attention mechanism, enabling complex feature extraction.\n",
    "- Layer Stacking: Multiple encoder layers are stacked to build a hierarchical representation of the sequence. Each layer refines the features extracted by the previous one.\n",
    "\n",
    "• Dropout Regularization\n",
    "Dropout is applied at multiple stages in the model, including:\n",
    "- After the embedding and positional encoding layers.\n",
    "- Within the transformer encoder to prevent overfitting during self-attention and feedforward computations.\n",
    "- Before the final fully connected layer to regularize the final feature representations.\n",
    "\n",
    "• Key Padding Mask\n",
    "To ensure the model processes variable-length sequences effectively, a key padding mask is generated. This mask prevents the transformer from attending to padded tokens, maintaining the integrity of the attention mechanism and avoiding noise in the learned representations.\n",
    "\n",
    "• Fully Connected Layer\n",
    "The final layer of the model is a fully connected layer that maps the output of the transformer encoder to the desired output dimension (POS tag probabilities). Each token's contextual representation is transformed into logits, which can be further processed using a softmax function during training to compute probabilities for each POS tag.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STransformerE(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_heads, hidden_dim, num_layers, output_dim, padding_idx, embedding_matrix, dropout=0.1):\n",
    "        super(STransformerE, self).__init__()\n",
    "        \n",
    "        # Embedding Layer for Token Representations\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        # Parameter Layer for Embedding Initialization w/ Pre-Trained Embedding Matrix\n",
    "        self.embedding.weight = nn.Parameter(embedding_matrix)\n",
    "        self.embedding.weight.requires_grad = True  # Gradient Enabling for Fine-Tuning\n",
    "        # Positional Encoding Layer for Input Embedding Augmentation\n",
    "        self.pos_encoder = SPositionalEncoding(embedding_dim)\n",
    "        # Transformer Encoder Layer for Contextual Feature Extraction\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=hidden_dim, \n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        # Transformer Encoder Module for Multi-Layer Encoding\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers, norm=nn.LayerNorm(embedding_dim))\n",
    "        # Dropout Layer for Regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Fully Connected Layer for Mapping Encoded Features to Output Dimension\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Token Embeddings of Input Sequence\n",
    "        embedded = self.embedding(x)\n",
    "        # Addition of Positional Encoding to Token Embeddings\n",
    "        embedded = self.pos_encoder(embedded)\n",
    "        # Dropout of Embedded Tokens\n",
    "        embedded = self.dropout(embedded)\n",
    "        # Key Padding Mask Generation for Transformer Encoder\n",
    "        src_key_padding_mask = (x == self.embedding.padding_idx)\n",
    "        # Contextual Feature Extraction w/ Transformer Encoder\n",
    "        transformer_output = self.transformer_encoder(\n",
    "            embedded, \n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )\n",
    "        # Dropout of Transformer Output\n",
    "        transformer_output = self.dropout(transformer_output)\n",
    "        # Transformation of Encoded Features → Logits for POS Tags\n",
    "        logits = self.fc(transformer_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_dim = len(pos2idx)\n",
    "padding_idx = word2idx['<PAD>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code defines a function to train the model for one epoch. It iterates over the training data, computes predictions, calculates loss, performs backpropagation, and updates the model parameters. It also tracks accuracy.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, iter, optimizer, criterion, device):\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for sentences, pos_tags, lengths in tqdm(iter, desc=\"Training\", leave=False):\n",
    "        sentences = sentences.to(device)\n",
    "        pos_tags = pos_tags.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = net(sentences)\n",
    "        \n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        pos_tags = pos_tags.view(-1)\n",
    "        \n",
    "        loss = criterion(predictions, pos_tags)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        preds = torch.argmax(predictions, dim=1)\n",
    "        mask = pos_tags != pos2idx['<PAD>']\n",
    "        correct += (preds[mask] == pos_tags[mask]).sum().item()\n",
    "        total += mask.sum().item()\n",
    "        \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return epoch_loss / len(iter), accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code defines a function to evaluate the model on the validation set. It computes loss and accuracy without updating the model parameters.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(net, iter, criterion, device):\n",
    "    net.eval()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for sentences, pos_tags, lengths in tqdm(iter, desc=\"Evaluating\", leave=False):\n",
    "            sentences = sentences.to(device)\n",
    "            pos_tags = pos_tags.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            predictions = net(sentences)\n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            pos_tags = pos_tags.view(-1)\n",
    "            \n",
    "            loss = criterion(predictions, pos_tags)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(predictions, dim=1)\n",
    "            mask = pos_tags != pos2idx['<PAD>']\n",
    "            correct += (preds[mask] == pos_tags[mask]).sum().item()\n",
    "            total += mask.sum().item()\n",
    "            \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return epoch_loss / len(iter), accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code utilizes Optuna to perform hyperparameter tuning. It defines an objective function that trains the model with different hyperparameters and returns the best validation accuracy. The study is then optimized over a specified number of trials.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    num_heads = trial.suggest_categorical('num_heads', [4, 5, 8, 10])\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 256, 1024)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 6)\n",
    "    dropout = trial.suggest_uniform('dropout', 0.1, 0.5)\n",
    "\n",
    "    net = STransformerE(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        num_heads=num_heads,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        output_dim=output_dim,\n",
    "        padding_idx=padding_idx,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    net = net.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pos2idx['<PAD>'])\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    num_epochs_tuning = 10\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for epoch in range(num_epochs_tuning):\n",
    "        train_loss, train_acc = train_epoch(net, train_iter, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate_epoch(net, val_iter, criterion, device)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_acc = val_acc\n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='maximize', study_name='POS_Tagger_Hyperparam_Tuning')\n",
    "# study.optimize(objective, n_trials=20)\n",
    "# best_trial = study.best_trial\n",
    "# best_params = best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best Hyperparameters:\")\n",
    "# for key, value in best_trial.params.items():\n",
    "#     print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code initializes the model with the best hyperparameters obtained from tuning. It then trains the model for a specified number of epochs, saving the best model based on validation loss. Training and validation metrics are recorded for visualization.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "net = STransformerE(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    # num_heads=best_params['num_heads'],\n",
    "    num_heads=5,\n",
    "    # hidden_dim=best_params['hidden_dim'],\n",
    "    hidden_dim=507,\n",
    "    # num_layers=best_params['num_layers'],\n",
    "    num_layers=4,\n",
    "    output_dim=output_dim,\n",
    "    padding_idx=padding_idx,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    # dropout=best_params['dropout']\n",
    "    dropout=0.16140237719136658\n",
    ")\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pos2idx['<PAD>'])\n",
    "# optimizer = torch.optim.AdamW(net.parameters(), lr=best_params['lr'], weight_decay=0.01)\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=0.001102590574546097, weight_decay=0.01)\n",
    "num_epochs = 20\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5214, train acc: 0.5689, val acc: 0.8139\n",
      "\n",
      "epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6047, train acc: 0.8162, val acc: 0.8589\n",
      "\n",
      "epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4409, train acc: 0.8623, val acc: 0.9032\n",
      "\n",
      "epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3549, train acc: 0.8876, val acc: 0.9151\n",
      "\n",
      "epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3038, train acc: 0.9025, val acc: 0.9218\n",
      "\n",
      "epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2693, train acc: 0.9127, val acc: 0.9302\n",
      "\n",
      "epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2422, train acc: 0.9223, val acc: 0.9307\n",
      "\n",
      "epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2275, train acc: 0.9270, val acc: 0.9334\n",
      "\n",
      "epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2094, train acc: 0.9313, val acc: 0.9349\n",
      "\n",
      "epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1999, train acc: 0.9348, val acc: 0.9356\n",
      "\n",
      "epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1876, train acc: 0.9384, val acc: 0.9335\n",
      "\n",
      "epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1785, train acc: 0.9414, val acc: 0.9416\n",
      "\n",
      "epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1676, train acc: 0.9440, val acc: 0.9376\n",
      "\n",
      "epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1642, train acc: 0.9457, val acc: 0.9434\n",
      "\n",
      "epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1506, train acc: 0.9493, val acc: 0.9435\n",
      "\n",
      "epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1471, train acc: 0.9513, val acc: 0.9429\n",
      "\n",
      "epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1441, train acc: 0.9510, val acc: 0.9420\n",
      "\n",
      "epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1351, train acc: 0.9556, val acc: 0.9433\n",
      "\n",
      "epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1364, train acc: 0.9545, val acc: 0.9437\n",
      "\n",
      "epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1354, train acc: 0.9546, val acc: 0.9447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nepoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss, train_acc = train_epoch(net, train_iter, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate_epoch(net, val_iter, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(f\"train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, val acc: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(net.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABrK0lEQVR4nO3dd3yT1eLH8U+SJune0BYolC17i4CKCspQBCcqV5biVeE60KvivaLo7wouxL2uuPdEhYsgCCpLQBBEluzRFkop3U2aPL8/0oaWFmihbVL6fb9eeeXJk/M8OaehzZdzTs5jMgzDQEREREROyuzrCoiIiIjUFgpOIiIiIhWk4CQiIiJSQQpOIiIiIhWk4CQiIiJSQQpOIiIiIhWk4CQiIiJSQQpOIiIiIhWk4CQiIiJSQQpOIiIiIhXk0+D0008/MWTIEBo0aIDJZOLrr78+6TGLFi2ia9eu2O12WrRowdtvv13t9RQREREBHwennJwcOnXqxEsvvVSh8jt27ODSSy/lwgsvZO3atdx1113cfPPNfP/999VcUxEREREw+ctFfk0mE1999RXDhg07bpn777+f2bNn88cff3j3XXfddWRkZDB37twaqKWIiIjUZbVqjtOyZcvo379/qX0DBgxg2bJlPqqRiIiI1CUBvq5AZaSkpBAXF1dqX1xcHJmZmeTl5REUFFTmmIKCAgoKCryP3W436enpxMTEYDKZqr3OIiIi4t8MwyArK4sGDRpgNp+4T6lWBadTMXXqVKZMmeLraoiIiIif27NnD40aNTphmVoVnOLj40lNTS21LzU1lfDw8HJ7mwAmTZrExIkTvY+PHDlC48aN2bFjB2FhYdVa38oY8uIy0nMdvD2qKy3jqrZeTqeTH3/8kQsvvBCr1Vql5/ZnarfaXReo3Wp3XVDd7c7KyqJp06YVygW1Kjj16tWLOXPmlNo3f/58evXqddxj7HY7dru9zP7o6GjCw8OrvI6nqn5MFEdc2bhtocTExFTpuZ1OJ8HBwcTExNS5XzS1W+0+06ndanddUN3tLj5nRabw+HRyeHZ2NmvXrmXt2rWAZ7mBtWvXsnv3bsDTWzRy5Ehv+VtvvZXt27dz3333sWnTJl5++WU+/fRT7r77bl9Uv0pFh9gASM91+LgmIiIicjw+DU6rVq2iS5cudOnSBYCJEyfSpUsXJk+eDEBycrI3RAE0bdqU2bNnM3/+fDp16sQzzzzDf//7XwYMGOCT+lclb3DKVnASERHxVz4dqrvgggs40TJS5a0KfsEFF7BmzZpqrJVvFAenw7lOH9dEREREjqdWreN0JisOTodyCk5SUkRERHxFwclPeIfqcjRUJyIi4q8UnPyEd6guR0N1IiIi/krByU9EaahORETE7yk4+YkY9TiJiIj4PQUnP1Hc45RdUIij0O3j2oiIiEh5atXK4Wey8MAAAswmCt0G6TkO4iMCfV0lERGpjQygeAHsw8BvgBuw4PnUt5TYbggkFJUtAPYdU67kvR2w1UgL/JqCk58wmUxEh9g4kFWg4CQiUlflA0fKuXUGmnuKhO0KwzLOAlnHlMkoup8OjC863zqg/wle7zHg30Xbm4pe53geAKYWbf8FtKZ0sCp5tZLbgGlF2/uLyh7PaOCFou0MoJxr7AYQQJORTWDwCc5TQxSc/EhUUXDSBHERkXJkA4eAHDBlmIhdH4vJYvL0phQAFwKxRWVXAQuL9hffHCW2/wm0LSr7LfBMiedLlnMBbwCDisrOAu7gaEgwlbiBJ7QMLdpewNEAYyrnmIeBa4r2zQGuKHrt8rwE3O7ZtGXaML9zgpk2R0ps1wPa4wk3hUXtKSyxHXnMsaHHlCu5RrWlxHYhnp/78eqbX2LbwPPeHc+xH3k5ZYuYMGEu9I/ZRQpOfkQTxEWkVir+cC0OBpl4eg5yim7ZJW45wNVARFHZWUW37GPKFm9/D7QrKvss4LkiFwEE0Ic+pevxM3Bu0fYvwP0nqPN1HA1OqcDiE5QtGQKygd3HK0jpgJAFbD5B2cMltoMoHULC8fyMim+xR5/KaZCD6zEXlmiLJ/hEHL8sbYH1J6hDSZ2K6lySG0+IclF6VnQLPMN6hSWeLymixHYcnh6qkkr2ToUds729bNWcTid7Vu+hDW1O2ISaoODkR6K0CKaInIyB58Mqr+h27AfdOmBP0XP5JcoVP57E0XkqbwGL8HxgO4vuHSUezwKii8pOAd4+plzRtsvl4vAfhwlrFYY9wA7/gS1vbmFJ4hJPlU2lL61lxBnQoGh7rQG/e7atLiujfh/lLTen5Rz2/rmXC+IvoFVMKwiBnfV3MrfNXAy7QYG7gKCQICwBFswBZiyHLJh/N2M2mTHHmbHc7tlvDjAz1DQUi90CNlhnXUdKcAqtMlqRFJkEF0HWh1msc6/DbDVjtpmx2CyYbWbMFjOWRAuWgxYsJguWcyyYF5k924aFeFs8ASbPR2l+YT7Opk7sLjs2i80T4ooDmVHiVvy45PDVOcAuPIEjjFIhJb8wn2xHNrYCG0HmIPJj8nGOcLI5czNOl5NCdyFOd9G9y0lhsudx8XOF7kJchgvDMLio6UUkhHkmNW1O28ySPUtoEtGEfs36eV/v9dWvU+guxDAMDAzchtu7bRhFj4/ZHtJqCO3qexLuhgMb+GDdBzSOaMyt3W/1JI3m8MAPD3A477C3Pi7DhcvtOvrYXXbf+B7jubLNleCEwo2F+AMFJz+i1cNFarniXpLccm6FwBBPMYfLQfI7yezbvo/9jv1YC6wMTR/qCTe5MDppNIfOO8S0ftM8H0ZjYPWK1fxU7yfCcsIIzw8nrCCMMEcY4QXhHJhxgLTcNKJDorFPtcPHJ6jjHRwNTsuAd0s/7TQ7ORR8iENBhzi07RBpqWkcyj1EWl4ah1p59oc4Q3hxzoveYzrd3okNn21gwcgFXNT0IrDDz81+5uZLby6/DquLbsUu99yFmcIY9eAoz3BRKDz3x3PM+3Me77Z61xOc7oZ1l67jto9vK/+8a4tuxeof3cz7Vx6WAM9Y01NfPcX7C9/nacvT3NP7HmgGG2wbOPfNc6msXXftonFEYwAe/P5Bnv3vs9zf536m9Z8GsbC9w3ZaPN8Ci9kTvMwms3fbsspzb2AcDT1FIei3W36jU3wnAJ5e+jQP/fgQ47qO46WBLwGQWZBJu5fbHbdex/P93773BqfFuxbz9+/+ztDWQ0sFp/FzxlPorlxISQxP9AanrelbmfrLVHo16uUJTkXeW/ce+7P2V+q8l7W8rFLla4KCkx+JDlZwEqkRh/AMJx07hJSNZx7H9SXKPoZn0mzJcsVhKJTSH9QDIevXLHZG7mRf+D72he3z3u+P3M++/fvYl7WPAzkHPOWtnlvnzM4MfX+o9zQ/3vUju7fsZvL5ReNS2bAwaiH3XXRf+e3ZjHdIyNbaRtiDYYS5wmhe0Jwftv/gGQYKhGmx00j9OZVxvcbRtl5buAo+bfopT7ue5pBxiDQjjUwj8+h555R4jSCgt2czPjCeF5990VN/G0TPjoZkyMjP8BR4FBJHJXLpiku9h5tMJcdmPHNWjn0uKCDIM4xXpLe7N8GpwSRGJBYfREJoAle2uRK3201KSgr14+p7e0VK3lyGq9Rji+noBJ3G4Y3pHN+ZuNA47z6bxUbL6JZlji3ZC1Lefcnzug3PUjJm09HuIpfb5Q1GhVQ8jJQMLlaztew+i5XY4FgCzAFYzVbPvcVa7uMAcwAWk8XzJaSgaO85mkQ0YXDLwXRL6Fbqta846wpchguzyYwJEyaT6aTbzaKaeY9vHtWcO3veSdPIpqXOe0+ve8hx5HiDY4A5oNxti9nirXPXhK4V/pnVFJNhGMbJi505MjMziYiI4MiRI4SHh/u6OqV8vnovD8/aQN9W9Xj5b1X3j8XpdDJnzhwGDx6M1WqtsvP6O7X7+O12G27yC/PJc+aRV5hHnjMPh8vh7d4/9r5heEM6xnUEoKCwgPfWvUehu5Bbut3i/ZD4cuOXrEleU/45iraP/VDr0aAHD573oLdegz8YTIGrgI+v+ph6IfUgA55b/hwfbf0It8uNy+XC7XLjdrtxmVy4Q0uc75CbwvxCQk2hdM7pzAfrPvCGnXF9x5HRP4Op/abSIroFtIdFOYv4vvn32F127IX2o/dhdgKfDcRusWMPsGO/1479D89zYY4w2h9o763vwwMeZsu4LUzrN40mkU1gAExxTOGRCx456ftkw0YDVwMamhrSztyO10Jfg2AgCL4u/Jq0zmlc0fYKYoJjYAd889c3fLz/YzJdmWS5sjw3ZxaZ+Zlk5GXgMMr+h6t1TGs2TdjkfdzxlY6sP7CeeX+bx8XNLwY8wzJ//+7vpY4zYSIqKIrY4FhigmI898Ex3u24kDjGdBnjLX8k/wjB1mCslpr7PfPH3+/iXiOL2eIZqival5abdsIAZjaZywSf2OBY78/T5XZ5Q4o/trsmVHe7K5MN1OPkRzRUVzvtz9rvDQUl/+dbcvz/2H0JYQnEh8YDkO3IZn3qemwWG90aHP2f36r9qziSfwQDo0zIOd79wBYDGdZqGAC7j+zmuq+uw2axsWTsEu95B38wmP/99b9KtXFs57G8OfRNAApcBYz7dhwAozuPJjAgEAz46o+veP/P9yt13sLlhfAQ3p6chdcupMBcQF5hnqdAB9jVbhcreq0o/wQlJ+2a8PSKABEHI0pN9p19+WyS/0zmwXOLQlooLI1byrTzplGur0psdy+6Ac2szdjWfpsn4ATDZ8s/Y+MfG7m5y82e4PQdNFrfiOgfomkY1pCG4Q099yW3i+5jg2PL9MIUG8aw0juawuVNL+fy4jGtEoo/UC4ZeAn57nyyHFlkFWSRWZBZ5vy3dr+V3Ud2e8JjkUuaX8Ks62Z5Q1JMcAxRgVFYzJZjX+q4IgIjTl6oDiju3Tl2X/Hv+qmqzHsh1U/ByY9oqM5/uA03B3MOEmQNItzu+d/HmuQ1PLv8WeqH1OfpS572lj135rnsyNhRqfNP6zeN+8/1fOVnU9omes/sTWJ4IrvvPvp1nfFzxvPrvl8rdd6ooChvcAJP+LJb7KXKHPtH2Gq2Emjx9LBYA6xYLVasZivWLCtWt+fWeEVjz7BNJtgz7VzW9TKs7a14O6yjoX+T/kQ0jMDq8hxjc9k8242sWG/znNdismD+txlzhhmLYaFJRhPYdrQub618C56AmKAYz44QGPvHWC48eCHmQDNmuxlzoBmL3YI5wYz5Ps9EYIvJgvG5we4/d1O/dX3Cu4XDJXjnyjxx5Aky4zK9c1FYCj129OCurXdR4CqgoLCAAlcB+YX5pR4fe984ojEls8sdtjvIdeYeHaawwtguY7mp602Vet+qQoA5gCh7FFFBUcctc3uP28vsS4pM8kyQFpEKUXDyI9GhRcEpV8GpOhW6C0nJTmFv5l7vbV/mPvZmlX7sdDt5/bLXGdfN07uSkZ/Be+veo3VM61LBKTAgkMCAQM83eYrG+80mc6nxf+9zRftCbCGljm8W1YwGYQ1K1bN5VHNynbmYMGEPsBMUEESQNaj0fUAQQUYQQYVBBDmDOCfvHEzfmWi0uBHxO+L5tum3BJ1b1A3jAgbCWzlvYWQaBKUHEXQoCIujKEgNBmaXqEAInnk8x7Bj59vMbz1zf4oFwajfRzFq3SjP16hL3kKh1LfGB+FZtyUEb7Ap3r4++nroUKLsH9A+oD3tac/JOP/h5NCcQ/Qd3LdMV/6N3Fi6sBkubn6xd7jqVJWc+FrseL1IInJmUHDyI8U9TnkOF3kOF0E2dc+eisN5h1m5fyUOZ+kAetmHl7E2ZS3J2cneSZwnYsJEel6693Hbem2Z1m9aqUmQAH+O//O06tu+fnu23VGi28UF/Akf2j70bO8C0vCsi5OBJ4T8X1FZB57LIByjG54hv8suuwxGFu20AEsgNi+27AFmPOu1lDSsqC7FASiixHbiMWXX4Ak/wZz8CpgTT/J8SfoLJSJ+Rn+W/EiI3YItwIyj0M3hXAdBtiBfV8mn3IabjPwMDuQcOOntvj73MbbLWAD+OPAHA94fQIvoFjzd+GjPUHJ2Mvuy9gGeYY3i+SaNwhvRKKyR577o1jC8IQmhCaUmu8aFxnmH105LBrCzxG0X0ArPJQrAM2+n4wmODy2xbcMTVpx4FsKLBHeEmzRnGrHNYzH3PCbFvAsEHi3rXTwvlNIL0gF8UMH2gGeBOxGROkDByY+YTCaig22kZOZzKMdBg8gzOzglZyXzv7/+R4A5gJGdRnr3D/pgEL+n/M7B3IMVXktk95Gjc4MSwhLoGNeRphGlvwr70uCXCDAH0Ci8EfVD6pf6ynCVMYB0PGHIBHQp2u8AeuAJSpnlHHcJR4NTCJ4gFQokAU3wrEcTWXRLOubYQ3h6nYqCj8vpYtmcZQwePBiz9Zg2Xo2IiJwGBSc/Ex3iCU7p2bV7npNhGBzMPcimtE1sTtvsuT+0mbFdxnpWgQW2Hd7GTd/cRPOo5qWC08GcgyRnJ3sfRwZGUj+k/tFbcP3Sj0Pq0zKmpbd8i+gW/H7r795vGxU7p9E5VdtIN57rUu3kaM/RTo5ecuESPJeLAE/P0D6OhqZ6eAJQEp5gVBywip3oMg3H0vWgRURqjIKTn/EuSVBLJog7XA62pW/zBqOS997F8EpoV6+dNzg1jmjM4JaDSYpIKlXmtctew2wyUz+kPvVC6nnXQ6kxTjzXotoO7Ci6L761BD4qKmfGc6Xw9HLOEQ8c++Wm4stXNMbTqyQiIrWOgpOf8QYnP+pxMgyDtNw0dh3ZRfcG3b37r/jkCr7d/C0u49irO3qYMJEUmUTr2Na0jmnNWbFn0Tuxt/f5xhGNmX3D7DLHlVzLqFoYwEGOhiITngt+FmtY9Hx5jr0u2K1F50viaO9RY7zrCZXSp5x9IiJSqyg4+Zni4HTYhz1OKdkp7Di8g16JvQDYdWQXTZ9rit1iJ+fBHO86QEEBQbgMF6G2UM6KPcsbjorvW0S3IMjqJ/O0HsJz8dPiXqScEs+dRenglIgnIDUDmhbdF2+3oLT/VFN9RUTELyk4+ZmoEM+3uA75YBHMgsICZiyfwX9+/g+DWw72BqfE8ESCAoKIC43jYO5B7yq4j/d7nKcveZqE0ATfrl1TiOdaYr/h+Vr8Gjy9SPNKlJldtL+YCU/PUjOgzTHnW4jnK/dajkdERI6h4ORnYkI8i/LU5FCdYRh8velr7p1/L9sPbwcoNfxmMVs4fP9h7AGlFwzy+WrDU/AEovWUvvQGeC4+WvJHeBeeSdvFvUdNKHf9I8Dz9XwREZFyKDj5meIep5oaqluXuo675t7Fjzt/BKBBWAOm9ZvGiI4jSpU7NjTViCN4rjxf3Iu0BVjC0QUW/wRWFm2HAp2Brni+odaF0v+6RyIiInLaFJz8TPEcp+oeqjuYc5B/L/w3/13zX9yGm8CAQO7tdS/3n3s/obbQk5+gunwKfIYnKG0r5/kdQPOi7duAq/CEpOaUXbHaWU11FBGROkvByc8UD9UdznFgGEaVzx1yuBy8sOIFHv3pUTILPIsKXdvuWp7s/6Tn6u41wYWn5+gHPPOSZuJZ4BE8PUyflyjbmKM9SF0ovUL1BdVcTxERkWMoOPmZ4qG6gkI3uQ4XIfaqeYsMw+C7rd9x/4L72Zq+FYCuCV2ZMWAG5zU5r0pe44QKgZ/whKIvgdQSz60BBhRtD8Wz/lFxUIqp/qqJiIhUlIKTnwm2BRBktZDndJGe46iy4LQ5dzMPfPYAAPGh8Tx+0eOM6jyqei47cqx5wAg8F6otFglcCpxD6W+19Sy6iYiI+CEFJz8UFWIlL8MTnBKjg0/5PIXuQgLMnre4dXBrhrQaQrt67XjwvAcJs4dVVXVLKwDm4wlG5xbta4knNMUAV+C5XtqFeC5DIiIiUosoOPmh6BAb+zPyT3mCeKG7kJd+fYnnVjzHiptXEGmLxGQy8flVn2OzVUNaycNzTbbPgW/xXI9tCEeDU1NgKZ6L3OpfnIiI1GI1ME4jlVVygvipMGHi7d/fZkfGDl5Z9crR/VW9SOWXeFbcroenJ+kDPKGpAdD6mLK9UGgSEZFaTx9lfqh4gnh6JYLT5rTNJEYkEmwNxmK28OKgF9lwcAM3dbkJt8tdNRXLBwJLPH4W+KVoOxHPENzVeOYtKZKLiMgZSB9vfsh7od8KBKfDeYe5a+5dtH+lPU8vfdq7v0/jPtzS7RbvdeVOWQbwHp5vu8VSeoL334F/AiuAXcB0oDf6VyUiImcs9Tj5oejgkwenQnchr69+nck/TuZQ3iEANqZtrJq1n/KAj/HMWZpP6YUk5wE3FG3/7fReRkREpLZRcPJD0aEnDk4/bP+Bu7+/mz8O/AFAu3rteHbAs1zc/OLTf/FfgeHAzhL72nJ0GK796b+EiIhIbaXg5IeO1+O0LX0b98y7h1mbZwEQExTDoxc+yi3dbvEuO3DaGuIZjmuIZyjuKjzBSURERBSc/NGxPU7Zjmwe//lxnln2DA6XgwBzAON7jOfhvg8TFRR1ei+WA3wDXF/0uCEwG8/Fcn14yToRERF/pODkh7wX+s3N593f3+WBHx4gOTsZgEuaX8KMATNoU6/NiU5xcgae5QTuBvbgWVKgf9Fz55/eqUVERM5UCk5+qHio7pB7AaO+9nxTrnlUc6YPmM6QVkNOf/L3JuAOPBO/AZrgCVIiIiJyQgpOfsYwDOxWCyF2C0ZBX2LqLeCGjtdy9zl3Yw+wn97Js4FpeNZfcgJ24D7gAeDUr+wiIiJSZyg4+QmHy8HzK57n0w2f8svYX4gOtpFT4GLm4Pl0T4o5/RcwwDLYAsuLHl8KPAc0P/1Ti4iI1BVaqtBP5DnzeGrpU6zcv5KP1n/kneeUkVtYNS9gAvcdbmiG53py36HQJCIiUknqcfKhnRk7aRLRBJPJRERgBM8PfJ5cZy43drqRXzesBSA999SuV0cmMAXoAIzw7DKuMuBKPEN0IiIiUmnqcfKBI/lHuHfevbR8oSWfbPjEu394++GM6TIGs8lMTPFlV7IrGZwM4H08F9mdjueSKNlFz5lQaBIRETkNCk41yG24mblmJq1ebMUzy56h0F3Iwh0Lyy1bPFR3uDI9Tr/jWUrgRiAFaInnOnNaj0lERKRKaKiuhizbs4w75t7Bqv2rAGgV04oZA2YwqOWgcstHFa/lVIEL/ZIBTAZeAtx4viH3b2Ainh4m53GPFBERkUpQcKpm+zL38cCCB3h/3fsAhNvDmXz+ZP7R8x/YLLbjHlepobotwAtF29cAzwCJp1VtERERKYeCUzXJL8xn+rLpPP7z4+Q4czBhYmyXsfznov8QFxp30uOjTjZUdwCoX7R9NvAo0Iujq3+LiIhIlVNwqmKGYTBr8yzumXcP2w9vB6BXo148P+h5ujfoXuHzRB9vqK4QuBN4C1gHtCja/9Dp1lxERERORsGpij234jnu/v5uABqENeDJ/k9yQ4cbKn2ZlKPrODlxuw3M5qLj3wReLir0DZ55TCIiIlIjfP6tupdeeomkpCQCAwPp2bMnv/766wnLz5gxg9atWxMUFERiYiJ33303+fn5NVTbkxvRYQRxIXE8eO6DbJ6wmREdR5zSteWiiq5X53IbZOaXmN39ZdH9Iyg0iYiI1DCf9jh98sknTJw4kVdffZWePXsyY8YMBgwYwObNm6lfv36Z8h9++CEPPPAAM2fOpHfv3mzZsoXRo0djMpmYPn26D1pQVr2Qeuy4cwdB1qDTOo8twEx4YACZ+YWk5ziIDLZ5vj1XvHrB9adbUxEREaksn/Y4TZ8+nXHjxjFmzBjatm3Lq6++SnBwMDNnziy3/NKlS+nTpw833HADSUlJXHLJJVx//fUn7aWqaacbmooVTxBPL57n9D88c5zaAK2q5CVERESkEnwWnBwOB6tXr6Z//6NfAzObzfTv359ly5aVe0zv3r1ZvXq1Nyht376dOXPmMHjw4Bqpc00rM0H866InhvmiNiIiIuKzobq0tDRcLhdxcaW/mh8XF8emTZvKPeaGG24gLS2Nc889F8MwKCws5NZbb+XBBx887usUFBRQUFDgfZyZmQmA0+nE6fTvlSEjgzxvT1pmHs48JwHfB2DCROFlhRhOo8LnKW6nv7e3qqndanddoHar3XVBdbe7Muc1GYZR8U/gKrR//34aNmzI0qVL6dWrl3f/fffdx+LFi1mxYkWZYxYtWsR1113H//3f/9GzZ0/++usv7rzzTsaNG8dDD5X/ffxHHnmEKVOmlNn/4YcfEhwcXHUNqgZf7QpgZVoA/RKc9Gvgwp5hp/7q+uy5cI8fTOsXERE5M+Tm5nLDDTdw5MgRwsPDT1jWZ8HJ4XAQHBzM559/zrBhw7z7R40aRUZGBrNmzSpzzHnnncc555zDU0895d33/vvvc8stt5CdnY3ZXDZNlNfjlJiYSFpa2kl/OL724o/b+O8vuxjevSGTBrU+5fM4nU7mz5/PxRdfjNVqrcIa+je1W+2uC9RutbsuqO52Z2ZmEhsbW6Hg5LOhOpvNRrdu3ViwYIE3OLndbhYsWMCECRPKPSY3N7dMOLJYLIBn4cny2O127HZ7mf1Wq9Xv/9HVC/dMMs/IK6ySutaGNlcHtbtuUbvrFrW7bqmudlfmnD5djmDixImMGjWK7t27c/bZZzNjxgxycnIYM2YMACNHjqRhw4ZMnToVgCFDhjB9+nS6dOniHap76KGHGDJkiDdAnUmKJ4dHrrfCa8AI4CafVklERKRO82lwGj58OAcPHmTy5MmkpKTQuXNn5s6d650wvnv37lI9TP/+978xmUz8+9//Zt++fdSrV48hQ4bwn//8x1dNqFbRRYtgtl0RDj8C8Sg4iYiI+JDPL7kyYcKE4w7NLVq0qNTjgIAAHn74YR5++OEaqJnvRYd6glOP36M9O4b5ri4iIiKi72b5tahgG03TQmhyMATDZsBAX9dIRESkblNw8mNRwVb6bfZcesZ5gRv8+0uAIiIiZzwFJz8WYDFzyVbPfK+Mi+vWYmciIiL+SMHJn+2HdnsicGOw97xcX9dGRESkzvP55HA5gQxY1z6D/Cw3h4ILTlpcREREqpd6nPxZW5j5r52MvXEl6bkOX9dGRESkzlNw8nPRITYME6RnKziJiIj4mobq/NUWIOjo6uGHczU5XERExNfU4+SvJgONodd3MQAcytEcJxEREV9TcPJHBcAcz6azuxuAwznqcRIREfE1BSd/9COQBSSAuacJgPQczXESERHxNQUnf/R10f1QiA7zzHHSUJ2IiIjvKTj5Gzcwq2h72NHJ4Zl5hThdbl/VSkRERFBw8j+/Ail4rkt3IUQEWTF7RuvI0DfrREREfErByd98XXQ/GLCBxWwiMtjT66R5TiIiIr6ldZz8zSSgM9D46K7oEBvpOQ4FJxERER9TcPI3EcB1pXcVz3PSBHERERHf0lBdLeBdPVxrOYmIiPiUgpM/uQn4D3Cw9O7i4KShOhEREd/SUJ2/2A/MLNoeW/qpqGAroOAkIiLia+px8hffFN2fAySUfiom1A4oOImIiPiagpO/+LrofljZp9TjJCIi4h8UnPzBEWBh0fawsk/HhKjHSURExB8oOPmD/wFO4Cygddmno0M1OVxERMQfKDj5gxLXpitP8VBddkEhjkJdr05ERMRXFJz8QWjRbVj5T4cHWgkoumCdep1ERER8R8HJH7wBpAE9yn/abDYRWdTrdDhXwUlERMRXFJz8hZ0Tvhvey65kKziJiIj4ioKTL7mBjYBx8qJaPVxERMT3FJx86VegLdCTk4YnBScRERHfU3Dypa+L7psDphMXVXASERHxPQUnX/q66H7YyYsWBydNDhcREfEdBSdf2QRsBqzAoJMX1+RwERER31Nw8pXiRS/7AeEnL64eJxEREd9TcPKVr4vuh1WsuOY4iYiI+J6Cky8kA8uLti+v2CHeoToFJxEREZ8J8HUF6qRoYDawBkio4CFFwSnP4SLP4SLIZqmu2omIiMhxKDj5gh0YXHSroFB7AFaLCafL4HCugyBbUHXVTkRERI5DQ3W1hMlk0jwnERERH1NwqmlzgQeAtZU/VMFJRETEtzRUV9PeBj4p2u5cuUOjgjVBXERExJfU41STCoA5RdvDKn94TGjRWk4KTiIiIj6h4FSTFgFZQDxwduUP11CdiIiIbyk41aSvi+6Hcko/+eKhOgUnERER31Bwqilujl5mZdipnaJ4qE7BSURExDcUnGrKSjwrhocBF57aKdTjJCIi4lv6Vl1N2QvUAy7CswDmKYjRHCcRERGfUnCqKVfhGaLLOPVTRJUIToZhYDKZqqBiIiIiUlEaqqtJFiDm1A8v/lZdQaGbXIerauokIiIiFabgVBNS8UwOP03BNguBVs9bpuE6ERGRmqfgVBOGAY2An07vNCaTyTtBXItgioiI1DwFp+qWDCwvum9x+qcrHq7TZVdERERqnoJTdfum6L4n0OD0T6fVw0VERHzH58HppZdeIikpicDAQHr27Mmvv/56wvIZGRmMHz+ehIQE7HY7rVq1Ys6cOSc8xqe+LrofVjWnU3ASERHxHZ8uR/DJJ58wceJEXn31VXr27MmMGTMYMGAAmzdvpn79+mXKOxwOLr74YurXr8/nn39Ow4YN2bVrF5GRkTVf+YrIBBYUbQ+rmlMqOImIiPiOT4PT9OnTGTduHGPGjAHg1VdfZfbs2cycOZMHHnigTPmZM2eSnp7O0qVLsVqtACQlJdVklSvnf4ATaA2cVTWnLA5Oh3MVnERERGqaz4bqHA4Hq1evpn///kcrYzbTv39/li1bVu4x33zzDb169WL8+PHExcXRvn17Hn/8cVwuP13T6Oui+2FVd8r6YZ5lxzfsy8TtNqruxCIiInJSPutxSktLw+VyERcXV2p/XFwcmzZtKveY7du3s3DhQkaMGMGcOXP466+/uP3223E6nTz88MPlHlNQUEBBQYH3cWZmJgBOpxOn01lFrSmf6XYTpngT7ivdnp6nKtC7WRShdgvb03JY8GcyF7Sud9JjittZ3e31N2q32l0XqN1qd11Q3e2uzHlNhmH4pNti//79NGzYkKVLl9KrVy/v/vvuu4/FixezYsWKMse0atWK/Px8duzYgcViATzDfU899RTJycnlvs4jjzzClClTyuz/8MMPCQ4OrqLW1Ky5ewP4KTWAxBA3t7Z2oCuviIiInLrc3FxuuOEGjhw5Qnh4+AnL+qzHKTY2FovFQmpqaqn9qampxMfHl3tMQkICVqvVG5oA2rRpQ0pKCg6HA5vNVuaYSZMmMXHiRO/jzMxMEhMTueSSS076w/FXZ2cXMPj5ZezJgfrtetEjKeqE5Z1OJ/Pnz+fiiy/2zg2rC9RutbsuULvV7rqguttdPBpVET4LTjabjW7durFgwQKGDRsGgNvtZsGCBUyYMKHcY/r06cOHH36I2+3GbPZMz9qyZQsJCQnlhiYAu92O3W4vs99qtVbfPzo3MAm4GLiAKv8pJ0RZuaJrQz5ZuYe3l+2md8uy30AsT7W22Y+p3XWL2l23qN11S3W1uzLn9Ok6ThMnTuSNN97gnXfeYePGjdx2223k5OR4v2U3cuRIJk2a5C1/2223kZ6ezp133smWLVuYPXs2jz/+OOPHj/dVE8q3CngSuAKopnnrY/okYTbBkr8O8ef+iidlEREROXU+XY5g+PDhHDx4kMmTJ5OSkkLnzp2ZO3eud8L47t27vT1LAImJiXz//ffcfffddOzYkYYNG3LnnXdy//33+6oJ5fu66H4wULazq0okRgczqEMCs9cl89+ftzN9eOfqeSERERHx8mlwApgwYcJxh+YWLVpUZl+vXr1Yvnx5NdfqNH1ddD+sel/m5vOaMntdMvP+TGXXoRyaxIRU7wuKiIjUcT6/5MoZZzOwEbDi6XGqRq3iwujbqh6GAW/+sqN6X0xEREQUnKrcrKL7C4GI6n+5m89r6nnZtftJzcyv/hcUERGpwxScqtrXRffDaublujaJoluTKApdBu8s3VkzLyoiIlJHKThVpTygeFmqy2vuZccV9Tp9umovGbqGnYiISLVRcKpKQcBfwCagYc297LktY2kdH0aew8WHK3bX3AuLiIjUMQpOVc0EtK7hlzSZvHOdPlixm1xHYc1WQEREpI5QcDpDXNI2jsToIDJynXy+aq+vqyMiInJGUnA6QwRYzIw919Pr9M7SXTgK3T6ukYiIyJlHwekMMrRTA2JDbaRk5jN7XbKvqyMiInLGOeXg9Ndff/H999+Tl5cHgGEYVVYpOTV2q4VRvZMAz4KYLrfeExERkapU6eB06NAh+vfvT6tWrRg8eDDJyZ6ejZtuuol77rmnyisolTO8RyLhgQHsSMthwcbUkx8gIiIiFVbp4HT33XcTEBDA7t27CQ4O9u4fPnw4c+fOrdLKSeWF2AO4vmdjAP778w71BIqIiFShSgenefPm8cQTT9CoUaNS+1u2bMmuXbuqrGJy6v52ThMCrWY27M9k+fZ0X1dHRETkjFHp4JSTk1Oqp6lYeno6dru9Siolpyc6xMZVXT3B9o2ftvu4NiIiImeOSgen8847j3fffdf72GQy4Xa7efLJJ7nwwgurtHJy6kb3SSLAbGLFjnTW78v0dXVERETOCAGVPeDJJ5+kX79+rFq1CofDwX333ceGDRtIT09nyZIl1VFHOQUNIoO4tGMCs9bu560lu+gf6usaiYiI1H6V7nFq3749W7Zs4dxzz2Xo0KHk5ORw5ZVXsmbNGpo3b14ddZRTVLwg5sLNBzmQZ/JxbURERGq/Svc4AURERPCvf/2rqusiVaxF/VD6tanPgo0H+Ck1gNG+rpCIiEgtV+ng9NNPP53w+fPPP/+UKyNV7+bzmrJg4wHWHjKTfCSfxrFWX1dJRESk1qp0cLrgggvK7DOZjg4DuVyu06qQVK2OjSI5OymKX3ce5t3lu/n3Ze18XSUREZFaq9JznA4fPlzqduDAAebOnUuPHj2YN29eddRRTtOYPk0A+Oq3/aTnOHxcGxERkdqr0j1OERERZfZdfPHF2Gw2Jk6cyOrVq6ukYlJ1zmkaRcNgN/ty4f3lu7ijX0tfV0lERKRWOuWL/B4rLi6OzZs3V9XppAqZTCb6xhcC8NGK3eQUFPq4RiIiIrVTpXuc1q1bV+qxYRgkJyczbdo0OnfuXFX1kirWNtJNk+hgdqXn8unKPYwpWqpAREREKq7Swalz586YTKYyF48955xzmDlzZpVVTKqW2QRj+jTmkW838c6yXYw4pwm2gCrrcBQREakTKh2cduzYUeqx2WymXr16BAYGVlmlpHpc2iGeVxfvJCUzn6/X7uPa7om+rpKIiEitUukuhyZNmpS6JSYmKjTVElaLmVG9Pd+wm/nLDlxu4yRHiIiISEkV6nF6/vnnK3zCO+6445QrI9Xvqm6NeHXxdvak5zFvQwqDOiT4ukoiIiK1RoWC07PPPluhk5lMJgUnPxdiD+Bv5zTmpR+38cbPOxjYPr7UAqYiIiJyfBUKTsfOa5La7YaejZm5ZCebU7L4ZWsa57Wq5+sqiYiI1Ar6WlUdFBls49rujQD4788KxSIiIhVV6W/VAezdu5dvvvmG3bt343CUvoTH9OnTq6RiUr1G9krigxW7WbXrMGt2H6ZL4yhfV0lERMTvVTo4LViwgMsvv5xmzZqxadMm2rdvz86dOzEMg65du1ZHHaUaxEcEMrRTA774bR9v/LSDl/+m4CQiInIylR6qmzRpEvfeey/r168nMDCQL774gj179tC3b1+uueaa6qijVJOx5zbFZILFWw6yJTXL19URERHxe5UOThs3bmTkyJEABAQEkJeXR2hoKI8++ihPPPFElVdQqk9SbAgXt40D4E3NdRIRETmpSgenkJAQ77ymhIQEtm3b5n0uLS2t6momNWLcec0A+N8fKew9nOvj2oiIiPi3Sgenc845h19++QWAwYMHc8899/Cf//yHsWPHcs4551R5BaV6tW0QTu/mMbjcBjN/2enr6oiIiPi1Sgen6dOn07NnTwCmTJlCv379+OSTT0hKSuLNN9+s8gpK9Rt3vqfX6as1+0jLLvBxbURERPxXpYPT448/Tnp6OuAZtnv11VdZt24dX3zxBU2aNKnyCkr165EURcdGETgK3by3bJevqyMiIuK3Kh2cDh48yMCBA0lMTOSf//wnv//+e3XUS2qQyWTyznX6+Nc9ZOU7fVwjERER/1Tp4DRr1iySk5N56KGHWLlyJV27dqVdu3Y8/vjj7Ny5sxqqKDXhgtb1aF4vhOyCQj7+dY+vqyMiIuKXTumSK1FRUdxyyy0sWrSIXbt2MXr0aN577z1atGhR1fWTGmI2m7i5qNfpvWW7yHe6fFwjERER/3Na16pzOp2sWrWKFStWsHPnTuLi4qqqXuIDgzrE0yAykEM5Dr5as8/X1REREfE7pxScfvzxR8aNG0dcXByjR48mPDyc7777jr1791Z1/aQGWS1mRvdJAuCtX3ZS6HL7tkIiIiJ+ptLBqWHDhgwePJi0tDRef/11UlNTmTlzJv369cNkMlVHHaUGXdmlEdEhNvZl5PHFb+p1EhERKanSF/l95JFHuOaaa4iMjKyG6oivBdksjO2TxNPztvD4nI0kRgXRu0Wsr6slIiLiFyrd4zRu3DiFpjPcqN5JDOoQT6HL4M6P17Jh/xFfV0lERMQvnNbkcDkzmc0mHr+iA+c0iybX4eK2935jd7quYyciIqLgJOWyBZh57rounBUfxqEcB7e8u4pDuhyLiIjUcQpOclyhgQG8emM3GkUFsSc9j9ve/42cgkJfV0tERMRnFJzkhOqF2Xntxm5EBVvZsD+Tuz5ei6NQyxSIiEjdpOAkJ5UUG8LLf+tKkNXC0m2HmDzrD9xuw9fVEhERqXEKTlIhHRtF8uzwTgSYTXz7ezLT52/xdZVERERqnIKTVNh5rerx6LB2ALy1ZCfvLN3p2wqJiIjUML8ITi+99BJJSUkEBgbSs2dPfv311wod9/HHH2MymRg2bFj1VlC8hnZuyN0XtwTgybmbmbM+2cc1EhERqTk+D06ffPIJEydO5OGHH+a3336jU6dODBgwgAMHDpzwuJ07d3Lvvfdy3nnn1VBNpdhN5zblb+c0BmDSl+tZvu2Qj2skIiJSM3wenKZPn864ceMYM2YMbdu25dVXXyU4OJiZM2ce9xiXy8WIESOYMmUKzZo1q8HaCoDJZOL+gWcxsL1ndfE7Pl7DxuRMX1dLRESk2lX6WnVVyeFwsHr1aiZNmuTdZzab6d+/P8uWLTvucY8++ij169fnpptu4ueffz7haxQUFFBQcHThxsxMzwe80+nE6XSeZgtqh+J2VnV7Hx1yFoey81m5M4O/v7uad8Z41nzyF9XVbn+ndqvddYHarXZXx/krwqfBKS0tDZfLRVxcXKn9cXFxbNq0qdxjfvnlF958803Wrl1bodeYOnUqU6ZMKbN/3rx5BAcHV7rOtdn8+fOr/JyDImFvkI3kHAej3ljC31s7CLVW+cuclupod22gdtctanfdonZXrdzcil9WzKfBqbKysrK48cYbeeONN4iNja3QMZMmTWLixInex5mZmSQmJnLJJZcQHh5eXVX1K06nk/nz53PxxRdjtVZ9qjnvggJGvrWa5CP5zEqrxxs3diHY5vt/WtXdbn+ldqvddYHarXZXpeLRqIrw6adbbGwsFouF1NTUUvtTU1OJj48vU37btm3s3LmTIUOGePe53Z5VrAMCAti8eTPNmzcvdYzdbsdut5c5l9VqrVP/6KD62twg2sobo7rzt/+uYMP+LO774k9eHNEFq8XnU+iAuvleg9pd16jddYvaXfXnrSiffrLZbDa6devGggULvPvcbjcLFiygV69eZcqfddZZrF+/nrVr13pvl19+ORdeeCFr164lMTGxJqsvJTSNDeGVEZ7VxX/5K43JszZgGFpdXEREziw+H0+ZOHEio0aNonv37px99tnMmDGDnJwcxowZA8DIkSNp2LAhU6dOJTAwkPbt25c6PjIyEqDMfql5HRMjeebaTvzjozV8s3Y/9ULtTLykla+rJSIiUmV8HpyGDx/OwYMHmTx5MikpKXTu3Jm5c+d6J4zv3r0bs9k/hnzk5Pq2rseUy9vx76//4M1fdlAvzM6NvZr4uloiIiJVwufBCWDChAlMmDCh3OcWLVp0wmPffvvtqq+QnJYrujYkLbuAGT9s5Ym5m4gNtTGoQ4KvqyUiInLa1JUj1eLm85pyQ8/GGEbR6uLbtbq4iIjUfgpOUi1MJhMPDDqLS9rF4XQZ3PGRVhcXEZHaT8FJqo3FbGLalR3okRRFToGLW99bzd7DFV9kTERExN8oOEm1slstPH99F1rFhZKW7eCWd1eTnuPwdbVEREROiYKTVLvwICuv3diNhIhAdh3K5fb3fyPXUejraomIiFSagpPUiPrhgbw+shsRQVbW7zvCPZ/8jtPl9nW1REREKkXBSWpMs3qhvDyiK4FWMz9tTeORbzbgdmt1cRERqT0UnKRGdW7sWV3cYjbx9Zr9jH17JbvTNWFcRERqBwUnqXEXtK7P41e2J8hqYeXOw1z50lLeX75LvU8iIuL3FJzEJy7r2ICvxvemR1IUeU4XU+dsYvRbK9l1KMfXVRMRETkuBSfxmcToYGaO7sFDl7Uh2GZh9a7DXPnyUt5ZuhOXep9ERMQPKTiJT5nNJq47uzFfj+/DOc2iyXe6eXLuZka++Ss70tT7JCIi/kXBSfxCw6gg/juqOw9f3pYQu4W1ezK48uWlzPxlh3qfRETEbyg4id8wmUxc2z2Rr8f3oU+LGByFbp6Zt4URb6zgrwPZvq6eiIiIgpP4nwaRQbx2YzceG9aOsMAA1u87wtWvLOWNn7ZTqEUzRUTEhxScxC+ZTCau7NqIr8f34fyWsThdBjN+2MoNb6xga2qWr6snIiJ1lIKT+LX4iEBe/ltXHr+yPeGBAWzYn8nVry7jlUXbdMkWERGpcQpO4vdMJhNDOzdk1oQ+XHhWPQpdBi8u/IvrX1/OppRMX1dPRETqEAUnqTXqhwfywvVdeOLqDkQEWdmYnMXwV5fz0sK/cBSq90lERKqfgpPUKiaTics6NmDWhD70b1OfQrfBy4u2Mfy1Zfy5X71PIiJSvRScpFaqF2ZnxnWdefqajkQFW9mSms11ry/n+QVb1fskIiLVRsFJai2TycSgDgnMmtCHAe3icLkNXlu8nWteXcYf+474unoiInIGUnCSWi8m1M704Z2ZPrwT0SE2/jqQzQ1vrOD5BdtwqvNJRESqkIKTnDEGtIvnmwl9GNQhHpfbYObSXTz/p40v1+ynwOnydfVEROQMoOAkZ5SoEBtPX9OJ56/vTEyIjUMFZh79bhP9p//Eyz/+xaHsAl9XUUREajEFJzkj9WsTx6zx5zC4kZOECDvpOQ5e+nEb/af/xORZf+jadyIickoUnOSMFWoP4Nw4F99O6MXT13SkfcNwHIVuvli9j6EvLuHW91azbNshDMPwdVVFRKSWCPB1BUSqW4DZzKAOCQxsH8+a3Rm8s3QnCzYd4Oetafy8NY1WcaGM7J3EpR0SsAXo/xIiInJ8Ck5SZ5hMJro2iaJrkyh2p+fy/rJdfLlmH1tSs/n3V38wY/4WbujZmOE9EokMtvm6uiIi4of032upkxpHB/PgpW1YcE9f7r64JfXD7KRlO3h+wV/0e2Yxj377JzvTcnxdTRER8TPqcZI6LSLIys3nNWNkryTmbUjh7aU72ZicxScr9/DJyj1c0Loeo3on0SMpCpPJ5OvqioiIjyk4iQC2ADOXdWrApR0TWLnzMO8s3cmizQe9t7YJ4Yzq3YQB7eOxWtRRKyJSVyk4iZRgMpk4u2k0ZzeNZkdaDu8t28Wstfv4MzmT+79Yz/SieVDXdE8kIsjq6+qKiEgN03+dRY6jaWwIk4e05YeJfbmjXwtiQ22kZhbw7Pyt9HtmMY/P3sju9FxfV1NERGqQepxETiIqxMbf+zZnTJ+mzFmfzDtLd7IlNZsPVuzmw193c37LelzWKYELWtcj2KZfKRGRM5n+yotUkC3AzLAuDRnauQHLt6fzztKd/Lw1jcVbDrJ4y0GCbBYuOqs+l3ZIoHeLGM2FEhE5Ayk4iVSSyWSiV/MYejWPYfvBbL5bl8ycdcnsOZzH7HXJzF6XTGSwlUvaxnFpxwS6No7CbNY38kREzgQKTiKnoVm9UO7o15J/XNSC9XuPMHt9Mv/7I4VD2Q4+XbWXT1ftJT48kEEd4rm0YwJnxYdpWQMRkVpMwUmkCphMJjomRtIxMZJ/DmjNyp2Hmb0umfl/ppKSmc9bS3by1pKdNIsNYXDHBAZ3iKdJTIivqy0iIpWk4CRSxQIsZu9Q3kOXteHnrWnMXp/Mos0H2Z6Ww4sL/+LFhX/RvmE4l3ZIYFCHBOqF2X1dbRERqQAFJ5FqZLda6N82jv5t48jOL2TBplRmr0tm+fZ0/tiXyR/7Mnny+82cnRTNpR0T6N82TutDiYj4MQUnkRoSGhjA0M4NGdq5IWnZBXy/IYU561JYuyeDFTvSWbEjnUe/+5PzW9bj0o4J9G1VjyCbxdfVFhGREhScRHwgNtTOiJ5NGNGzCfsO5zFnfTJz1iezJTWbhZsOsHDTAYJtFvq18Sxv0LNZDLYALW8gIuJrCk4iPtYwKohx5zdj3PnN2JKaxZx1ycxZn8K+jDy+/T2Zb39PJsBsolm9EM5KCKdNfBhtEsI5KyGMsEAN64mI1CQFJxE/0ioujFYXh3Fn/5b8vsezvMG8DSmkZTvYkprNltRsvilRPjEqyBOmEorCVHwYkYHqmRIRqS4KTiJ+yGQy0blxJJ0bR/Lg4LNIycxnY3IWm5Iz2ZicxcbkTJKP5LPncB57Ducx/89U77HRIVZiLFb+WrCNdo0iaZMQRmJUsBbhFBGpAgpOIn7OZDKREBFEQkQQF51V37s/I9fBpqIQtTHFc78zLYf0HCfpWNi6dBewC4AQu4XWcZ5eqeJhvub1QjVvSkSkkhScRGqpyGAb5zSP4ZzmMd59eQ4XG/cf5vMflhMQ24TNqdlsTc0mp8DFb7sz+G13hrdsgMVEi3qhRWEqjE6JkZwVH0aArrEnclxutxuHw+Gz13c6nQQEBJCfn4/L5fJZPWra6bbbarVisVTNt5QVnETOIEE2Cx0aRrCnnovBg8/CarVS6HKzIy3HO8S3MTmTzSlZZOYXsikli00pWXy15ujxnRpF0LVxFF2bRNGxUQQhdv2ZEAFwOBzs2LEDt9vtszoYhkF8fDx79uypU5dvqop2R0ZGEh8ff9o/N/1FFDnDBVjMtIwLo2VcGJd3bgB4/gjtz8j3Bqk/92eydk8GmfmFLN+ezvLt6QBYzCbOig+jS+NIujaJomvjKK1yLnWSYRgkJydjsVhITEzEbPZNz6zb7SY7O5vQ0FCf1cEXTqfdhmGQm5vLgQMHAEhISDituig4idRBJpOJhlFBNIwKon/bOADcboNtB7M9Q3q7DvPb7sPsz8hnw/5MNuzP5P3luwFIjA6ia+Mob5hqFhtSp/7nK3VTYWEhubm5NGjQgODgYJ/Vo3ioMDAwsM4Fp9Npd1BQEAAHDhygfv36pzVsp+AkIgCYzSZvz9TwHokAJB/JY403SGWwJTWLPel57EnPY9ba/QBEBls9Iaqxp0eqbYNwTTqXM07xvBqbzebjmsipKg68TqdTwUlEqkdCRBAJHYIY3MHTtZ2V7+T3PUf4bfdhftt1mPX7jpCR6+THTQf5cdNBAOwBZjo0jCga2oukU2Ik4br+npwh1Ltae1XVe+cXwemll17iqaeeIiUlhU6dOvHCCy9w9tlnl1v2jTfe4N133+WPP/4AoFu3bjz++OPHLS8iVScs0Mq5LWM5t2UsAI5CN5uSM4u+secJU4dznazadZhVuw4DYDJBy/qhdE6MpElMCAmRgTSIDKJhZBBRwVZ9EInUIklJSdx1113cddddPj2HL/k8OH3yySdMnDiRV199lZ49ezJjxgwGDBjA5s2bqV+/fpnyixYt4vrrr6d3794EBgbyxBNPcMkll7BhwwYaNmzogxaI1F22ADMdEyPpmBjJ6D5JGIbBzkO53jlSv+3KYHd6rnfV82MFWS0kRHiCVIPI4nvPdsPIIGJD7Vq4U+Q0XHDBBXTu3JkZM2ZUyflWrlxJSEhIlZyrtvJ5cJo+fTrjxo1jzJgxALz66qvMnj2bmTNn8sADD5Qp/8EHH5R6/N///pcvvviCBQsWMHLkyBqps4iUz2Qy0TQ2hKaxIVzVrREAadkFrNmdwYZ9R9iXkcf+jHz2Z+RxMLuAPKeL7Wk5bE/LKfd8VouJ+AhPiGoQGURCRCANo4JoEOF5HBdu17pTIqfJMAxcLhcBASePBPXq1auBGvk3nwYnh8PB6tWrmTRpknef2Wymf//+LFu2rELnyM3Nxel0Eh0dXe7zBQUFFBQUeB9nZmYCnslhTqfzNGpfexS3s660t5ja7R/tjrCbuaBlNBe0LP076ih0k5qZz/4j+SQfyfcEqhLbBzILcLoM72T08lhMJuqH20iICCQ+zE5+egDu3/fRIi6cJjHBBFmrZsE7f+Zv73dNqel2O51ODMPA7Xb7fB2n4vuT1WPMmDEsXryYxYsX89xzzwGwbds2du7cSb9+/fjuu++YPHky69evZ+7cuSQmJnLPPfewYsUKcnJyaNOmDf/5z3/o37+/95zNmjXjzjvv5M477wTAYrHw2muvMWfOHObNm0fDhg156qmnuPzyy0/ajuL67969mzvuuIOFCxdiNpsZMGAAzz//PHFxnm/8/v7779x9992sXr0ak8lEy5YteeWVV+jevTu7du3iH//4B0uWLMHhcJCUlMQTTzzB4MGDy7ym2+3GMIxyJ4dX5t+RT4NTWloaLpfL+8MpFhcXx6ZNmyp0jvvvv58GDRqUemNLmjp1KlOmTCmzf968eT79SqkvzJ8/39dV8Am12//ZgCQgyQrEem4uA7KccLjARIbDxGGHiYyS2w4TLgOSjxSQfKT4P0cBLPxmMwAmDCJtBvUCPbf6gQaxgW7qBxmE+LyvverVpve7KtVUuwMCAoiPjyc7OxuHw4FhGOQX+iZABQaYycrKOmm5Rx99lI0bN9K2bVtvB0VERAS5ubmA5/PzscceIykpicjISPbu3cuFF17IAw88gN1u5+OPP2bo0KH8+uuvJCZ6vmnrdrvJz8/3dkIATJkyhSlTpjB58mRef/11brzxRtatW0dUVFS59Sp5DrfbzeWXX05ISAjfffcdhYWF/POf/+Saa67hu+++A+CGG26gY8eOLFiwAIvFwvr16ykoKCAzM5Nbb70Vp9PJd999R0hICJs2bcJkMpWqXzGHw0FeXh4//fQThYWFpZ4r/plURK3+8zFt2jQ+/vhjFi1aRGBgYLllJk2axMSJE72PMzMzSUxM5JJLLiE8PLymqupTTqeT+fPnc/HFF2O11p1vN6ndZ3a73YbBoWyHp5cqI5+9h3NY/sdfFAZGs/NQHhl5Tg47TBx2wJZj/oZGBllpGhtcNKx49D4hIhBzLZusXlfe72PVdLvz8/PZs2cPoaGhBAYGkutwce7jC6v9dcvzwz+6Uz868qRfrAgPDyc4OJiIiAhatmzp3V/cafDYY48xdOhQ7/4mTZrQp08f7+MuXbrwv//9j0WLFjF+/HjAMyoUGBhY6vNzzJgxjB07FoCnnnqK1157jY0bNzJw4MBy61XyHPPnz+fPP/9k27Zt3nD23nvv0aFDBzZv3kyPHj3Yt28f9913H61atSIsLIwuXbp4z5WcnMyVV15Jr169AOjYseNxfx75+fkEBQVx/vnnl8kM5QWt4/FpcIqNjcVisZCamlpqf2pqKvHx8Sc89umnn2batGn88MMPJ/xB2e127PayKx1brdY69UcG6mabQe0+kzWIttEgOhTwfJA2yNrE4MHdsVqtpOc42HEwh21p2Ww/mMOOgzlsT8tmf0Y+GXlO1uw5wpo9R0qdL9BqJikmhKb1QmgWG0LzeqE0rRdCUkyI369NVRfe7/LUVLtdLhcmkwmz2Vx0891wHeCty6mULd4+++yzS+3Pzs7mkUceYfbs2SQnJ1NYWEheXh579uwpVe7Y83Xq1Mn7OCwsjPDwcNLS0k5Yv+JzbN68mcTERJo0aeJ9rn379kRGRrJ582Z69uzJxIkTueWWW3jnnXcYMGAA1157Lc2bNwfgjjvu4LbbbmP+/Pn079+fq6666riZwGw2YzKZyv03U5l/Qz4NTjabjW7durFgwQKGDRsGeLrwFixYwIQJE4573JNPPsl//vMfvv/+e7p3715DtRWR2iQ6xEZ0iI1uSaWHC3Idhew6lMu2g0WBKi2H7Qdz2Hkoh3yn23v9vpLMJmgU5emZahIT7J2onhAZSIOIICK1rEKdE2S1sPLf/Wr8dd1uA2de2W+onopjvx137733Mn/+fJ5++mlatGhBUFAQV1999Ukvanxs6DCZTFU6D+yRRx7huuuu48svv2ThwoU88sgjfPzxx1xxxRXcfPPNDBgwgNmzZzNv3jymTp3KM888wz/+8Y8qe/1j+XyobuLEiYwaNYru3btz9tlnM2PGDHJycrzfshs5ciQNGzZk6tSpADzxxBNMnjyZDz/8kKSkJFJSUgAIDQ0lNDTUZ+0Qkdoh2BZAm4Rw2iSUHqovdLnZl5HHthK9U9sPekJVdkEhu9Nz2Z1e/jyIQKvZs1hoUZjybkcEkhAZRHx4oN/3WEnlmEwmgm01/xHqdrvJzK94SLfZbN5Vz09myZIljB49miuuuALw9EDt3LnzVKpZYW3atGHPnj3s2bPHO1T3559/kpGRQdu2bb3lWrVqxe23384DDzzAiBEjeOutt7z1TExM5NZbb+XWW29l0qRJvPHGG2d2cBo+fDgHDx5k8uTJpKSk0LlzZ+bOneudML579+5S3X2vvPIKDoeDq6++utR5Hn74YR555JGarLqInEECLGaaxITQJCYEzjq63zAM0rId3h6qvYdzSS6aV5V8JI+0bAf5Tjc70jy9V+UxmSA21O4NU94eq4igoqAVSESQeq2k6iUlJbFixQp27txJaGjocb+BDtCyZUu+/PJLhgwZgslk4qGHHqr2bxD279+fDh06MGLECGbMmEFhYSG33347ffv2pXv37uTl5fHPf/6TK6+8ktjYWI4cOcLKlSu56qqrALjrrrsYNGgQrVq14vDhw/z444+0adOmWuvs8+AEMGHChOMOzS1atKjU4+pOvyIiJZlMJuqF2akXZuecZjFlnncUukk+kucJU0fySc7II6VoSYXi/QWFbg5mFXAwq4B1e4+U8yoQZLN4g1WjqGAaRwfTOMZznxgVhL0OLK0gVe/ee+9l1KhRtG3blry8PHbs2HHcstOnT2fs2LH07t2b2NhY7r///kpNmj4VJpOJWbNm8Y9//IPzzz8fs9nMwIEDeeGFFwDPcgeHDh1i9OjRpKamEhsby5VXXun9trzL5WL8+PHs3buX8PBwBg4cyLPPPlutdfaL4CQiUlvZAkr0VJXDMAwO5zrZn5HnDVbJ3vWqPCHrUI6DPIfLOzQIh0qdw2SC+PBAb5hqUiJUxYfVvQnhUnGtWrUqsy5iUlKSdz2oY/cvXFj6m4LF36YrdmznRXnnycjIOGGdjj1H48aNmTVrVrllbTYbH330kWeIMjOT8PDwUqNQxQGrJik4iYhUI5PJ5J2o3r5hRLll8p0uUjM9w3/7j3gW/NydnsvuQ7nsSs8hp8DlDVsrdqSXOT7CaufLtN9oEhtCk+iQoz1V0UE+mYcjcibTb5SIiI8FWi3H7bUyDIP0HId3cronTHnud6fnkpVfyBGniVW7Mli1K6PM8fXD7KWG/YrvI4KsBNssBNsCsFpMml8lUkEKTiIifsxkMhETaicm1E6XxqWXVjAMg4OZuXzy3QISz+rCviMFpULVkTwnB7IKOJBVwKpdh4/7GhaziSCrhWCbhSCbpfR2Ubgq3hdc9PyxzwXZSj8fYg8gxK6PGDnz6F+1iEgtZTKZiAq20TjUYHDH+DLr6WTklu6pKr7fcziPzHwnhS7P/BSX2yC7oJDsgsLyXuaU1Q+z0zIulFZxYd77ZrEhmugutZqCk4jIGSoy2EZksI2OjSLLfd7pcpPncJHndJHrcHm2HS5ynYVHHztd5BZ47o+WLfSUO/bYEs+5Dby9XUv+OjrZ3WI20SQ6mJZxobSMC6N1UahqGBmE2azhQvF/Ck4iInWU1WLGGmQmPKhqv5lnGJ4erG0HcthyIIutqdlsTc1iS2o2R/KcbE/LYXtaDt9vOHq5rSCbhZb1Q4/2UNX33EeF2Kq0biKnS8FJRESqlMlkIizQSufGkXRuHOndbxgGB7IK2JJaHKay2ZKaxbaD2eQ5XKzbe6TMOlexoTbvUF9xD1WzeiFosE98RcFJRERqhMlkIi48kLjwQM5rWc+7v9DlZld6rjdIFfdQ7TnsWZk9LfsQS7cdHe4zm6BxdDBBhVaWzvqTELvVOzE92Bbgnah+dEJ7iX1F94EBFg0NyilRcBIREZ8KsJhpXi+U5vVCGdg+3rs/p6CQbQey2VwUprakZrH1QDYZuU52HsoFLGxcl3LKrxtksxBsLRmoAkqFq+JvCwZaLUTaoE1YIRm5DgLdZswmEyYTpe7NJk84PHqvYHYmUnASERG/FGIPoGNiJB0TI737iq8d+Oe+w8z9ZRXNWp6FwwW5jqKJ6SUmq3v3OVzklthfrHgy/KHyLzFYSkKohUnnRXMgqwBzXtnVsstTNliZMFE2ZFksJs98M4sZa9F2gNk/19ZKSkrirrvu4q677vJ1VXxGwUlERGqN4msH9m4eQ8ZmF4N7NymzDMOJuN0G+YWlw1VeUcA69luCxfsKCt0EGE6CrAahtgDM1gDchoFhgNswcBueQFd8XxyrDANc3kuSVCxsHW0nZcKU1WLGajbhdIPbAPPJT8MFF1xA586dmTFjRqVe/3hWrlxJSEj5lxeqKxScRESkzjCbTUVDcpX7+MvPz2fHjh00iAoiMDDwuOWMEoHKoESwchu4ORqwPMHLwO2GQreB0+UuuhkUutwYhucC0o5CdzmvYiI1LwuL2VQmWNlKbAdYKtZjZRgGLpeLgIDj/0yKr0kXExOLARS63WB44qDnKQPwvJ7JVLzl2QZPTxul9vtfb1pFVSSwioiISAWYTCbMZhMBReHFHlA0Sd0eQKg9gLBAKxFBVqKCbUSH2IkNsxMfEUhidDDN6oXSOj6MNg3CaRUXRtPYEBpFBREXHkh0iI2wwAACrWaK57S73Ab5ThdZ+YWk5zhIzcxnz+E8tqflsDk1iyuGj2Dx4sU899xzmEyeob+fVm/gw6//h8lk4s2PvqR9py7Y7XY++mYe85f/Tr+BlxJbrz7BIaG079yVNz+exYb9R9iwP5MN+zNJbNKEBx+bxqbkLDalZGELsDD12ZcYdNlQIsJCadmyJa+++wmbUjzPb0zOYmNyJn8mZ/Jn0TmmPf867Tp1ISQ0jNj6cVx6xTX8sn4bG5Mz2ZScyeaULL5b/CsXXjyQ0LBwQkPDOLv3uazcuJOMPCcAM2fOpF27dtjtdhISEpgwYUKNvcfqcRIRETlVJ5ofZQFKdk6dqKwZCCraNJmwFZiwFfdtmItuVnAHucnMzCQ0LLxET1WJHqvCom23m/unTGPn9m20aN2GCfc+CEBETCzbtu8A4MnHJnPPQ/9HYuMkwiMiSUneS58LL2bCP/+NzWbnmy8+Yvzo6/j2p5UkNEw8btVfffYJJv77Ue596DE+eOs1HvjHLcxbvp6IqKhyyxcWOplw779Iat6S9LSDPPXov5h052288t5nAKQm7+NvwwbSo9e5vPnJN4SEhbFm5XLynYW43AavvPIKEydOZNq0aQwaNIgjR46wZMmSE/xwq5aCk4iIyKkKPcFzg4HZJR7XB3KPU7YvsKjE4yQgrZxyRXPbzSbPxaEDj3P5GsMwKIwLIzw4kHpR4XRuneTpdQL2hnvS3JQpjzLk8suAouG1Vo0YfEEvTHiG1C7u1Ylffvgffy7/kQvHj4eieVfx4YG0axDufa2bbxrDP28fC8D5nZ/hgzdfI3PPRnq3G0jxKJ5noM8zjDnprttL7W9a/3n69DqH+GAIDQ3lneffISoyks8/+wRrgBUDuKBHR7JzcggPtPJ///d/3HPPPdx5553eOvTo0eM4P9iqp+AkIiJyhjGZTFgtnmFDe4CZyOCjK7AXX3z5vN49S12IOTs7m0ceeYTZs2eTnJxMYWEheXl57Nu7hwCLudS5S85R6tix49Fzh4QQHh7OwYMHvUHNO7GpaGP16tU88sgj/P777xw+fBi32zOP60DyPmLbtmXD+nWcf/55RIQEec/rdrspzIfDhw6yf/9++vXrV0U/qcpTcBIRETlV2Sd47tjOoAMnKHvsjOOdp1SbSjn223H33nsv8+fP5+mnn6ZFixYEBQVx9dVX43A4TnieY7/VaDKZvGHoWDk5OQwYMIABAwbwwQcfUK9ePXbv3s2AAQO8rxMUFFTusSd7rqYoOImIiJyqynwzvyrKlp9Hjstms+FyuU5eEFiyZAmjR4/miiuuADw9UDt37qzcC57Epk2bOHToENOmTSMx0TNvatWqVaXKdOzYkXfeeQen01kmlIWFhZGUlMSCBQu48MILq7RuFaVv1YmIiJyhkpKSWLFiBTt37iQtLe24PUEALVu25Msvv2Tt2rX8/vvv3HDDDScsfyoaN26MzWbjhRdeYPv27XzzzTc89thjpcpMmDCBzMxMrrvuOlatWsXWrVt577332Lp1KwCPPPIIzzzzDM8//zxbt27lt99+44UXXqjSep6IgpOIiMgZ6t5778VisdC2bVvvsNjxTJ8+naioKHr37s2QIUMYMGAAXbt2rdL61KtXj7fffpvPPvuMtm3bMm3aNJ5++ulSZWJiYli4cCHZ2dn07duXbt268eabb3p7n0aNGsWMGTN4+eWXadeuHZdddpk3VNUEDdWJiIicoVq1asWyZctK7UtKSvIuaHns/oULF5baN378+FKPjx26K+88GRkZJ6zT9ddfz/XXX3/C83Ts2JHvv//e+9jt9izDUOzvf/87f//730/4OtVFPU4iIiIiFaTgJCIiIlJBCk4iIiIiFaTgJCIiIlJBCk4iIiIiFaTgJCIiIlJBCk4iIiIiFaTgJCIiIlJBCk4iIiIiFaTgJCIiIseVlJTEjBkzfF0Nv6HgJCIiIlJBCk4iIiIiFaTgJCIicgZ6/fXXadCgAW63u9T+oUOHMnbsWAC2bdvG0KFDiYuLIzQ0lB49evDDDz9U6nVWrlzJxRdfTGxsLBEREfTt25fffvutVJmMjAz+/ve/ExcXR2BgIO3bt+e7777zPr9kyRIuuOACgoODiYqKYsCAARw+fPgUW169FJxEREROUY4jp9K3Qneh9/hCdyE5jhzynHkVOm9lXHPNNRw6dIgff/zRuy89PZ25c+cyYsQIALKzsxk8eDALFixgzZo1DBw4kCFDhrB79+4Kv05WVhajRo3il19+Yfny5bRs2ZLBgweTlZUFgNvtZtCgQSxZsoT333+fP//8k2nTpmGxWABYu3Yt/fr1o23btixbtoxffvmFIUOG4HK5KtXemhLg6wqIiIjUVqFTQyt9zKdXf8o17a4B4KuNX3Ht59fSt0lfFo1e5C2T9FwSablpZY51PVTxMBEVFcWgQYP48MMP6devHwCff/45sbGxXHjhhQB06tSJTp06eY957LHH+Oqrr/jmm2+YMGFChV7noosuKvX49ddfJzIyksWLF3PZZZfxww8/8Ouvv7Jx40ZatWoFQLNmzbzln3zySbp3787LL7/s3deuXbsKt7OmqcdJRETkDDVixAi++OILCgoKAPjggw+47rrrMJs9H//Z2dnce++9tGnThsjISEJDQ9m4cWOlepxSU1MZN24cLVu2JCIigvDwcLKzs73nWLt2LY0aNfKGpmMV9zjVFupxEhEROUXZk7IrfYw9wO7dvqLNFWRPysZsKt2PsfPOnadbNQCGDBmCYRjMnj2bHj168PPPP/Pss896n7/33nuZP38+Tz/9NC1atCAoKIirr74ah8NR4dcYNWoUhw4d4rnnnqNJkybY7XZ69erlPUdQUNAJjz/Z8/5GwUlEROQUhdhCTuv4AHMAAbayH8XHO++xE71PJjAwkCuvvJIPPviAv/76i9atW9O1a1fv80uWLGH06NFcccUVgKcHaufOnZV6jSVLlvDyyy8zePBgAPbs2UNa2tFhxo4dO7J37162bNlSbq9Tx44dWbBgAVOmTKnU6/qKhupERETOYCNGjGD27NnMnDnTOym8WMuWLfnyyy9Zu3Ytv//+OzfccEOlw1nLli1577332LhxIytWrGDEiBGlepH69u3L+eefz1VXXcX8+fPZsWMH//vf/5g7dy4AkyZNYuXKldx+++2sW7eOTZs28corr5QKX/5EwUlEROQMdtFFFxEdHc3mzZu54YYbSj03ffp0oqKi6N27N0OGDGHAgAGleqQq4s033+Tw4cN07dqVG2+8kTvuuIP69euXKvPFF1/Qo0cPrr/+etq2bct9993n/dZcq1atmDdvHr///jtnn302vXr1YtasWQQE+OegmH/WSkRERKqE2Wxm//795T6XlJTEwoULS+0bP358qccnG7rr0qULK1euLLXv6quvLvU4OjqamTNnHvccffv2ZcmSJSd8HX+hHicRERGRClJwEhEREakgBScRERGRClJwEhEREakgBScRERGRClJwEhERqSDDMHxdBTlFVfXeKTiJiIichMViAajUpUjEv+Tm5gJgtVpP6zxax0lEROQkAgICCA4O5uDBg1itVu9Fcmua2+3G4XCQn5/vszr4wum02zAMcnNzOXDgAJGRkd4QfKoUnERERE7CZDKRkJDAjh072LVrl8/qYRgGeXl5BAUFYTKZfFaPmlYV7Y6MjCQ+Pv6066LgJCIiUgE2m42WLVv6dLjO6XTy008/cf7555/2kFNtcrrttlqtp93TVMwvgtNLL73EU089RUpKCp06deKFF17g7LPPPm75zz77jIceeoidO3fSsmVLnnjiCe9VmUVERKqL2WwmMDDQZ69vsVgoLCwkMDCwTgUnf2q3zwdIP/nkEyZOnMjDDz/Mb7/9RqdOnRgwYAAHDhwot/zSpUu5/vrruemmm1izZg3Dhg1j2LBh/PHHHzVccxEREalrfB6cpk+fzrhx4xgzZgxt27bl1VdfJTg4+LgXA3zuuecYOHAg//znP2nTpg2PPfYYXbt25cUXX6zhmouIiEhd49Pg5HA4WL16Nf379/fuM5vN9O/fn2XLlpV7zLJly0qVBxgwYMBxy4uIiIhUFZ/OcUpLS8PlchEXF1dqf1xcHJs2bSr3mJSUlHLLp6SklFu+oKCAgoIC7+MjR44AkJ6ejtPpPJ3q1xpOp5Pc3FwOHTrk87HhmqR2q911gdqtdtcF1d3urKwsoGKLZPrF5PDqNHXqVKZMmVJmf9OmTX1QGxEREfFXWVlZREREnLCMT4NTbGwsFouF1NTUUvtTU1OPu9ZCfHx8pcpPmjSJiRMneh+73W7S09OJiYmpM2tgZGZmkpiYyJ49ewgPD/d1dWqM2q121wVqt9pdF1R3uw3DICsriwYNGpy0rE+Dk81mo1u3bixYsIBhw4YBnmCzYMECJkyYUO4xvXr1YsGCBdx1113effPnz6dXr17llrfb7djt9lL7IiMjq6L6tU54eHid+kUrpnbXLWp33aJ21y3V2e6T9TQV8/lQ3cSJExk1ahTdu3fn7LPPZsaMGeTk5DBmzBgARo4cScOGDZk6dSoAd955J3379uWZZ57h0ksv5eOPP2bVqlW8/vrrvmyGiIiI1AE+D07Dhw/n4MGDTJ48mZSUFDp37szcuXO9E8B3795d6ro0vXv35sMPP+Tf//43Dz74IC1btuTrr7+mffv2vmqCiIiI1BE+D04AEyZMOO7Q3KJFi8rsu+aaa7jmmmuquVZnDrvdzsMPP1xmyPJMp3ar3XWB2q121wX+1G6TUZHv3omIiIiI71cOFxEREaktFJxEREREKkjBSURERKSCFJxqualTp9KjRw/CwsKoX78+w4YNY/PmzSc85u2338ZkMpW6BQYG1lCNq8YjjzxSpg1nnXXWCY/57LPPOOusswgMDKRDhw7MmTOnhmpbdZKSksq022QyMX78+HLL19b3+qeffmLIkCE0aNAAk8nE119/Xep5wzCYPHkyCQkJBAUF0b9/f7Zu3XrS87700kskJSURGBhIz549+fXXX6upBafmRO12Op3cf//9dOjQgZCQEBo0aMDIkSPZv3//Cc95Kr8rvnCy93z06NFl2jFw4MCTnrc2v+dAub/vJpOJp5566rjn9Pf3vCKfW/n5+YwfP56YmBhCQ0O56qqryix+faxT/btQWQpOtdzixYsZP348y5cvZ/78+TidTi655BJycnJOeFx4eDjJycne265du2qoxlWnXbt2pdrwyy+/HLfs0qVLuf7667nppptYs2YNw4YNY9iwYfzxxx81WOPTt3LlylJtnj9/PsAJv2VaG9/rnJwcOnXqxEsvvVTu808++STPP/88r776KitWrCAkJIQBAwaQn59/3HN+8sknTJw4kYcffpjffvuNTp06MWDAAA4cOFBdzai0E7U7NzeX3377jYceeojffvuNL7/8ks2bN3P55Zef9LyV+V3xlZO95wADBw4s1Y6PPvrohOes7e85UKq9ycnJzJw5E5PJxFVXXXXC8/rze16Rz627776bb7/9ls8++4zFixezf/9+rrzyyhOe91T+LpwSQ84oBw4cMABj8eLFxy3z1ltvGRERETVXqWrw8MMPG506dapw+Wuvvda49NJLS+3r2bOn8fe//72Ka1az7rzzTqN58+aG2+0u9/kz4b0GjK+++sr72O12G/Hx8cZTTz3l3ZeRkWHY7Xbjo48+Ou55zj77bGP8+PHexy6Xy2jQoIExderUaqn36Tq23eX59ddfDcDYtWvXcctU9nfFH5TX9lGjRhlDhw6t1HnOxPd86NChxkUXXXTCMrXtPT/2cysjI8OwWq3GZ5995i2zceNGAzCWLVtW7jlO9e/CqVCP0xnmyJEjAERHR5+wXHZ2Nk2aNCExMZGhQ4eyYcOGmqheldq6dSsNGjSgWbNmjBgxgt27dx+37LJly+jfv3+pfQMGDGDZsmXVXc1q43A4eP/99xk7duwJr7t4JrzXJe3YsYOUlJRS72dERAQ9e/Y87vvpcDhYvXp1qWPMZjP9+/ev1f8Gjhw5gslkOullpCrzu+LPFi1aRP369WndujW33XYbhw4dOm7ZM/E9T01NZfbs2dx0000nLVub3vNjP7dWr16N0+ks9d6dddZZNG7c+Ljv3an8XThVCk5nELfbzV133UWfPn1OuJJ669atmTlzJrNmzeL999/H7XbTu3dv9u7dW4O1PT09e/bk7bffZu7cubzyyivs2LGD8847j6ysrHLLp6SkeFejLxYXF0dKSkpNVLdafP3112RkZDB69OjjljkT3utjFb9nlXk/09LScLlcZ9S/gfz8fO6//36uv/76E167q7K/K/5q4MCBvPvuuyxYsIAnnniCxYsXM2jQIFwuV7nlz8T3/J133iEsLOykQ1a16T0v73MrJSUFm81W5j8EJ3rvTuXvwqnyi5XDpWqMHz+eP/7446Rj2b169Sp1UeTevXvTpk0bXnvtNR577LHqrmaVGDRokHe7Y8eO9OzZkyZNmvDpp59W6H9jZ4I333yTQYMGnfBq3mfCey1lOZ1Orr32WgzD4JVXXjlh2TPld+W6667zbnfo0IGOHTvSvHlzFi1aRL9+/XxYs5ozc+ZMRowYcdIveNSm97yin1v+RD1OZ4gJEybw3Xff8eOPP9KoUaNKHWu1WunSpQt//fVXNdWu+kVGRtKqVavjtiE+Pr7MNzJSU1OJj4+viepVuV27dvHDDz9w8803V+q4M+G9Ln7PKvN+xsbGYrFYzoh/A8WhadeuXcyfP7/SV4o/2e9KbdGsWTNiY2OP244z6T0H+Pnnn9m8eXOlf+fBf9/z431uxcfH43A4yMjIKFX+RO/dqfxdOFUKTrWcYRhMmDCBr776ioULF9K0adNKn8PlcrF+/XoSEhKqoYY1Izs7m23bth23Db169WLBggWl9s2fP79Ub0xt8tZbb1G/fn0uvfTSSh13JrzXTZs2JT4+vtT7mZmZyYoVK477ftpsNrp161bqGLfbzYIFC2rVv4Hi0LR161Z++OEHYmJiKn2Ok/2u1BZ79+7l0KFDx23HmfKeF3vzzTfp1q0bnTp1qvSx/vaen+xzq1u3blit1lLv3ebNm9m9e/dx37tT+btwOg2QWuy2224zIiIijEWLFhnJycneW25urrfMjTfeaDzwwAPex1OmTDG+//57Y9u2bcbq1auN6667zggMDDQ2bNjgiyacknvuucdYtGiRsWPHDmPJkiVG//79jdjYWOPAgQOGYZRt85IlS4yAgADj6aefNjZu3Gg8/PDDhtVqNdavX++rJpwyl8tlNG7c2Lj//vvLPHemvNdZWVnGmjVrjDVr1hiAMX36dGPNmjXeb49NmzbNiIyMNGbNmmWsW7fOGDp0qNG0aVMjLy/Pe46LLrrIeOGFF7yPP/74Y8Nutxtvv/228eeffxq33HKLERkZaaSkpNR4+47nRO12OBzG5ZdfbjRq1MhYu3Ztqd/3goIC7zmObffJflf8xYnanpWVZdx7773GsmXLjB07dhg//PCD0bVrV6Nly5ZGfn6+9xxn2nte7MiRI0ZwcLDxyiuvlHuO2vaeV+Rz69ZbbzUaN25sLFy40Fi1apXRq1cvo1evXqXO07p1a+PLL7/0Pq7I34WqoOBUywHl3t566y1vmb59+xqjRo3yPr7rrruMxo0bGzabzYiLizMGDx5s/PbbbzVf+dMwfPhwIyEhwbDZbEbDhg2N4cOHG3/99Zf3+WPbbBiG8emnnxqtWrUybDab0a5dO2P27Nk1XOuq8f333xuAsXnz5jLPnSnv9Y8//ljuv+vitrndbuOhhx4y4uLiDLvdbvTr16/Mz6NJkybGww8/XGrfCy+84P15nH322cby5ctrqEUVc6J279ix47i/7z/++KP3HMe2+2S/K/7iRG3Pzc01LrnkEqNevXqG1Wo1mjRpYowbN65MADrT3vNir732mhEUFGRkZGSUe47a9p5X5HMrLy/PuP32242oqCgjODjYuOKKK4zk5OQy5yl5TEX+LlQFU9GLi4iIiMhJaI6TiIiISAUpOImIiIhUkIKTiIiISAUpOImIiIhUkIKTiIiISAUpOImIiIhUkIKTiIiISAUpOImIiIhUkIKTiEglLFq0CJPJVOYCpCJSNyg4iYiIiFSQgpOIiIhIBSk4iUit4na7mTp1Kk2bNiUoKIhOnTrx+eefA0eH0WbPnk3Hjh0JDAzknHPO4Y8//ih1ji+++IJ27dpht9tJSkrimWeeKfV8QUEB999/P4mJidjtdlq0aMGbb75Zqszq1avp3r07wcHB9O7dm82bN1dvw0XELyg4iUitMnXqVN59911effVVNmzYwN13383f/vY3Fi9e7C3zz3/+k2eeeYaVK1dSr149hgwZgtPpBDyB59prr+W6665j/fr1PPLIIzz00EO8/fbb3uNHjhzJRx99xPPPP8/GjRt57bXXCA0NLVWPf/3rXzzzzDOsWrWKgIAAxo4dWyPtFxHfMhmGYfi6EiIiFVFQUEB0dDQ//PADvXr18u6/+eabyc3N5ZZbbuHCCy/k448/Zvjw4QCkp6fTqFEj3n77ba699lpGjBjBwYMHmTdvnvf4++67j9mzZ7Nhwwa2bNlC69atmT9/Pv379y9Th0WLFnHhhRfyww8/0K9fPwDmzJnDpZdeSl5eHoGBgdX8UxARX1KPk4jUGn/99Re5ublcfPHFhIaGem/vvvsu27Zt85YrGaqio6Np3bo1GzduBGDjxo306dOn1Hn79OnD1q1bcblcrF27FovFQt++fU9Yl44dO3q3ExISADhw4MBpt1FE/FuArysgIlJR2dnZAMyePZuGDRuWes5ut5cKT6cqKCioQuWsVqt322QyAZ75VyJyZlOPk4jUGm3btsVut7N7925atGhR6paYmOgtt3z5cu/24cOH2bJlC23atAGgTZs2LFmypNR5lyxZQqtWrbBYLHTo0AG3211qzpSISDH1OIlIrREWFsa9997L3Xffjdvt5txzz+XIkSMsWbKE8PBwmjRpAsCjjz5KTEwMcXFx/Otf/yI2NpZhw4YBcM8999CjRw8ee+wxhg8fzrJly3jxxRd5+eWXAUhKSmLUqFGMHTuW559/nk6dOrFr1y4OHDjAtdde66umi4ifUHASkVrlscceo169ekydOpXt27cTGRlJ165defDBB71DZdOmTePOO+9k69atdO7cmW+//RabzQZA165d+fTTT5k8eTKPPfYYCQkJPProo4wePdr7Gq+88goPPvggt99+O4cOHaJx48Y8+OCDvmiuiPgZfatORM4Yxd94O3z4MJGRkb6ujoicgTTHSURERKSCFJxEREREKkhDdSIiIiIVpB4nERERkQpScBIRERGpIAUnERERkQpScBIRERGpIAUnERERkQpScBIRERGpIAUnERERkQpScBIRERGpIAUnERERkQr6f48uH49tx82fAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(epochs_range, train_losses, label='train loss', linestyle='-', color='#2a7db8')\n",
    "plt.plot(epochs_range, train_accuracies, label='train acc', linestyle='--', color='magenta')\n",
    "plt.plot(epochs_range, val_accuracies, label='val acc', linestyle='-.', color='green')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('value')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code loads the best-performing model and defines a function to calculate evaluation metrics such as accuracy, precision, recall, and F1 score on the validation set.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_4860\\2640716579.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metrics(net, iter):\n",
    "    net.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentences, pos_tags, lengths in tqdm(iter, desc=\"Predicting\", leave=False):\n",
    "            sentences = sentences.to(device)\n",
    "            pos_tags = pos_tags.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            predictions = net(sentences)\n",
    "            predicted_indices = torch.argmax(predictions, dim=-1)\n",
    "            \n",
    "            for i in range(sentences.size(0)):\n",
    "                length = lengths[i]\n",
    "                pred = predicted_indices[i][:length].cpu().numpy()\n",
    "                label = pos_tags[i][:length].cpu().numpy()\n",
    "                all_preds.extend(pred)\n",
    "                all_labels.extend(label)\n",
    "    \n",
    "    pred_labels = [idx2pos[idx] for idx in all_preds if idx != pos2idx['<PAD>']]\n",
    "    true_labels = [idx2pos[idx] for idx in all_labels if idx != pos2idx['<PAD>']]\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(true_labels, pred_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(true_labels, pred_labels, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9429\n",
      "Precision: 0.9426\n",
      "Recall: 0.9429\n",
      "F1 Score: 0.9424\n"
     ]
    }
   ],
   "source": [
    "cal_metrics(net, val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "In here, the code defines a function to predict POS tags for a given input sequence. It tokenizes the input, converts words to indices, runs the model to obtain predictions, and constructs a parse tree with predicted POS tags. Additionally, it provides descriptions for each unique POS tag in the prediction.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pos_tag(net, word2idx, idx2pos, sequence):\n",
    "    net.eval()\n",
    "\n",
    "    pos_descriptions = {\n",
    "        \"CC\": \"Coordinating Conjunction\",\n",
    "        \"CD\": \"Cardinal Number\",\n",
    "        \"DT\": \"Determiner\",\n",
    "        \"EX\": \"Existential 'There'\",\n",
    "        \"FW\": \"Foreign Word\",\n",
    "        \"IN\": \"Preposition or Subordinating Conjunction\",\n",
    "        \"JJ\": \"Adjective\",\n",
    "        \"JJR\": \"Adjective (Comparative)\",\n",
    "        \"JJS\": \"Adjective (Superlative)\",\n",
    "        \"LS\": \"List Item Marker\",\n",
    "        \"MD\": \"Modal\",\n",
    "        \"NN\": \"Noun (Singular or Mass)\",\n",
    "        \"NNS\": \"Noun (Plural)\",\n",
    "        \"NNP\": \"Proper Noun (Singular)\",\n",
    "        \"NNPS\": \"Proper Noun (Plural)\",\n",
    "        \"PDT\": \"Predeterminer\",\n",
    "        \"POS\": \"Possessive Ending\",\n",
    "        \"PRP\": \"Personal Pronoun\",\n",
    "        \"PRP$\": \"Possessive Pronoun\",\n",
    "        \"RB\": \"Adverb\",\n",
    "        \"RBR\": \"Adverb (Comparative)\",\n",
    "        \"RBS\": \"Adverb (Superlative)\",\n",
    "        \"RP\": \"Particle\",\n",
    "        \"SYM\": \"Symbol\",\n",
    "        \"TO\": \"to\",\n",
    "        \"UH\": \"Interjection\",\n",
    "        \"VB\": \"Verb (Base Form)\",\n",
    "        \"VBD\": \"Verb (Past Tense)\",\n",
    "        \"VBG\": \"Verb (Gerund or Present Participle)\",\n",
    "        \"VBN\": \"Verb (Past Participle)\",\n",
    "        \"VBP\": \"Verb (Non-3rd-Person Singular Present)\",\n",
    "        \"VBZ\": \"Verb (3rd Person Singular Present)\",\n",
    "        \"WDT\": \"Wh-Determiner\",\n",
    "        \"WP\": \"Wh-Pronoun\",\n",
    "        \"WP$\": \"Possessive Wh-Pronoun\",\n",
    "        \"WRB\": \"Wh-Adverb\"\n",
    "    }\n",
    "\n",
    "    if isinstance(sequence, str):\n",
    "        words = nltk.word_tokenize(sequence)\n",
    "    elif isinstance(sequence, list):\n",
    "        words = sequence\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    words_lower = [word.lower() for word in words]\n",
    "    word_indices = [word2idx.get(word, word2idx['<UNK>']) for word in words_lower]\n",
    "\n",
    "    input_tensor = torch.tensor([word_indices], dtype=torch.long).to(device)\n",
    "    lengths = torch.tensor([len(word_indices)], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = net(input_tensor)\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    predicted_pos_indices = predictions[0][:lengths[0]].cpu().numpy()\n",
    "    predicted_pos_tags = [idx2pos[idx] for idx in predicted_pos_indices]\n",
    "            \n",
    "    word_pos_pairs = list(zip(words, predicted_pos_tags))\n",
    "    tree = Tree('S', [Tree(pos, [word]) for word, pos in word_pos_pairs])\n",
    "    tree.pretty_print()\n",
    "\n",
    "    ordered_unique_pos = []\n",
    "    for pos in predicted_pos_tags:\n",
    "        if pos not in ordered_unique_pos:\n",
    "            ordered_unique_pos.append(pos)\n",
    "        \n",
    "    print(\"Description:\")\n",
    "    for pos in ordered_unique_pos:\n",
    "        description = pos_descriptions.get(pos, \"Unknown POS tag\")\n",
    "        print(f\"{pos}: {description}\")\n",
    "        \n",
    "    return tree, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      S                    \n",
      "  ____________________|__________________   \n",
      " DT   JJ   NNP  NNP   NN   IN   DT NNP  NNP\n",
      " |    |     |    |    |    |    |   |    |  \n",
      "The quick brown fox jumps over the lazy dog\n",
      "\n",
      "Description:\n",
      "DT: Determiner\n",
      "JJ: Adjective\n",
      "NNP: Proper Noun (Singular)\n",
      "NN: Noun (Singular or Mass)\n",
      "IN: Preposition or Subordinating Conjunction\n"
     ]
    }
   ],
   "source": [
    "pos_tree = predict_pos_tag(net, word2idx, idx2pos, \"The quick brown fox jumps over the lazy dog\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
